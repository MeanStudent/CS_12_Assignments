{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adagrad, Adadelta, RMSprop, Adam, Nadam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0' \n",
    "\n",
    "from pyimagesearch.minigooglenet import MiniGoogLeNet\n",
    "from pyimagesearch.clr_callback import CyclicLR\n",
    "from pyimagesearch import config\n",
    "from pyimagesearch.learningratefinder import LearningRateFinder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_witdth, img_height = 32, 32\n",
    "\n",
    "((trainX, trainY), (testX, testY)) = fashion_mnist.load_data()\n",
    "# ((trainX, trainY), (testX, testY)) = cifar10.load_data()\n",
    "trainX = trainX.astype(\"float\")\n",
    "testX = testX.astype(\"float\")\n",
    "\n",
    "# apply mean subtraction to the data\n",
    "mean = np.mean(trainX, axis=0)\n",
    "trainX -= mean\n",
    "testX -= mean\n",
    "\n",
    "# Fashion MNIST images are 28x28 but the network we will be training\n",
    "# is expecting 32x32 images\n",
    "trainX = np.array([cv2.resize(x, (img_witdth, img_height)) for x in trainX])\n",
    "testX = np.array([cv2.resize(x, (img_witdth, img_height)) for x in testX])\n",
    "\n",
    "# scale the pixel intensities to the range [0, 1]\n",
    "trainX = trainX.astype(\"float\") / 255.0\n",
    "testX = testX.astype(\"float\") / 255.0\n",
    "\n",
    "\n",
    "# reshape the data matrices to include a channel dimension (required\n",
    "# for training)\n",
    "\n",
    "trainX = trainX.reshape((trainX.shape[0], img_witdth, img_height, 1))\n",
    "testX = testX.reshape((testX.shape[0], img_witdth, img_height, 1))\n",
    "\n",
    "\n",
    "# convert the labels from integers to vectors\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)\n",
    "\n",
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = trainX.shape[0]\n",
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x_dataset = tf.data.Dataset.from_tensor_slices(trainX)\n",
    "# train_y_dataset = tf.data.Dataset.from_tensor_slices(trainY)\n",
    "# test_x_dataset = tf.data.Dataset.from_tensor_slices(testX)\n",
    "# test_y_dataset = tf.data.Dataset.from_tensor_slices(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def loss(model, x, y):\n",
    "#     y_ = model(x)\n",
    "#     return keras.losses.categorical_crossentropy(y_true=y, y_pred=y_)\n",
    "\n",
    "# def grad(model, x, y):\n",
    "#     with tf.GradientTape() as tape:\n",
    "#         loss_value = loss(model, x, y)\n",
    "#     return loss_value, tape.gradient(loss_value, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 18:04:55.976846: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-11-09 18:04:55.976992: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n",
      "\n",
      "systemMemory: 64.00 GB\n",
      "maxCacheSize: 24.00 GB\n",
      "\n",
      "[<tf.Variable 'conv2d/kernel:0' shape=(3, 3, 1, 96) dtype=float32, numpy=\n",
      "array([[[[-0.04024583,  0.07023236,  0.01231268,  0.05246894,\n",
      "           0.01729498, -0.08155982, -0.07855324, -0.02086258,\n",
      "           0.06944911, -0.04135326,  0.07815564, -0.03839624,\n",
      "           0.06725414, -0.03657682, -0.01275507,  0.01205456,\n",
      "          -0.05488753,  0.08085696,  0.04139505,  0.05291864,\n",
      "          -0.0746337 ,  0.0122546 , -0.01350466, -0.06046361,\n",
      "           0.02179006, -0.0610294 ,  0.02633017,  0.02099525,\n",
      "          -0.08094639, -0.0121751 ,  0.04624033, -0.05897267,\n",
      "          -0.03394994, -0.07591308,  0.02787472,  0.01307666,\n",
      "           0.05991745,  0.0112219 ,  0.05701442, -0.07357065,\n",
      "          -0.0209321 , -0.01888042,  0.03746057, -0.02795456,\n",
      "          -0.05248944, -0.00087717,  0.02508041, -0.01758304,\n",
      "           0.05107524, -0.05827594,  0.04682577, -0.04182708,\n",
      "           0.08145563,  0.00954646,  0.02460448, -0.01780331,\n",
      "           0.02198386, -0.08035586, -0.00710332,  0.03949332,\n",
      "           0.02625575,  0.01079022,  0.05867738, -0.0725227 ,\n",
      "           0.0796617 ,  0.00841045,  0.02293096, -0.04060057,\n",
      "          -0.02359602,  0.03358687,  0.02672902,  0.03772447,\n",
      "           0.04279175,  0.05522351,  0.0757214 ,  0.04514974,\n",
      "           0.06868638, -0.00696868,  0.02306512,  0.0560801 ,\n",
      "          -0.03320932,  0.01541574, -0.02290387, -0.01813502,\n",
      "          -0.02832654,  0.03086805, -0.01512959, -0.03236626,\n",
      "           0.00663661, -0.0654078 , -0.02711476, -0.0133533 ,\n",
      "           0.04234202,  0.03372096, -0.04802765,  0.07806979]],\n",
      "\n",
      "        [[ 0.00075767,  0.06679283,  0.008186  ,  0.02645832,\n",
      "          -0.0584626 ,  0.02133002,  0.05882911,  0.01971675,\n",
      "          -0.06126639, -0.06065035, -0.06639965, -0.00053211,\n",
      "          -0.04866773, -0.02804801,  0.02784812, -0.05133823,\n",
      "          -0.01253664,  0.02760728,  0.04574111, -0.01345543,\n",
      "          -0.07417832,  0.05542593,  0.05884832,  0.00462765,\n",
      "          -0.04800519, -0.01085979, -0.06353438, -0.01410147,\n",
      "          -0.00682354,  0.01606444,  0.02604402,  0.04433338,\n",
      "           0.06119147, -0.08157279,  0.00993963,  0.05894785,\n",
      "           0.06427577,  0.06519289, -0.04910224, -0.01092172,\n",
      "          -0.04054329, -0.07507601,  0.0354807 , -0.02889014,\n",
      "           0.0401853 ,  0.048539  , -0.08250353, -0.00161777,\n",
      "          -0.02951188, -0.0766299 , -0.01732619, -0.04008576,\n",
      "           0.00913986,  0.06810196, -0.0579339 , -0.00357985,\n",
      "           0.03964328, -0.01178212, -0.04959252, -0.06490421,\n",
      "          -0.03529334, -0.02878734, -0.04072432,  0.06856053,\n",
      "          -0.06338683, -0.01876566,  0.07404301,  0.02475549,\n",
      "          -0.07126154,  0.08091597, -0.05247527, -0.02858038,\n",
      "          -0.06813042,  0.06503038, -0.07875033, -0.05781262,\n",
      "          -0.02222044,  0.04709314, -0.0331609 , -0.08178099,\n",
      "          -0.01173413, -0.03424229, -0.03356281, -0.03679189,\n",
      "          -0.06561721,  0.00574841,  0.07063542, -0.07848517,\n",
      "           0.05447134,  0.03667448,  0.05931059,  0.00590705,\n",
      "           0.08173202,  0.03109147, -0.00559768,  0.06410873]],\n",
      "\n",
      "        [[ 0.02452552, -0.03891741,  0.01700694, -0.00228525,\n",
      "           0.01910112,  0.00081214, -0.03550234,  0.06722994,\n",
      "           0.05909485,  0.03885086, -0.05732201,  0.07901534,\n",
      "           0.07598619, -0.06728795, -0.05453351,  0.02663428,\n",
      "          -0.02337779,  0.00992123, -0.0194355 , -0.01776791,\n",
      "           0.04978108,  0.0542461 , -0.04986519,  0.02668812,\n",
      "           0.07528539, -0.00077738, -0.03427834, -0.062481  ,\n",
      "           0.01811964,  0.0192074 ,  0.04953846,  0.06684771,\n",
      "           0.05631314,  0.03927497, -0.04597794, -0.00380077,\n",
      "          -0.02952341,  0.01461168,  0.00138877,  0.04215862,\n",
      "          -0.05622279,  0.00135771,  0.08012392, -0.03870023,\n",
      "           0.02260219, -0.04980538, -0.00345733,  0.02402857,\n",
      "          -0.0724756 ,  0.03755387,  0.06670657, -0.01170897,\n",
      "           0.0133434 ,  0.01649371,  0.00232037, -0.05065895,\n",
      "          -0.08002558,  0.0776426 , -0.05119272, -0.01931553,\n",
      "           0.06175861, -0.04105318,  0.06381963,  0.0076602 ,\n",
      "          -0.04116076,  0.00117073, -0.03374175,  0.07751268,\n",
      "           0.04960111,  0.0717303 ,  0.05212533,  0.04997684,\n",
      "          -0.05427118,  0.05454308,  0.01173255,  0.05376145,\n",
      "          -0.05769513, -0.02105219,  0.07971737, -0.01260545,\n",
      "           0.0025885 ,  0.02228082,  0.00556324, -0.05506248,\n",
      "           0.06299828,  0.01169414, -0.05182933,  0.05177075,\n",
      "          -0.06352877, -0.06358872, -0.0681522 , -0.06205548,\n",
      "           0.01179483,  0.06011099,  0.02595956, -0.05016604]]],\n",
      "\n",
      "\n",
      "       [[[ 0.00080491, -0.06466129, -0.04629328,  0.0342735 ,\n",
      "           0.05424996,  0.0523091 ,  0.04207077,  0.00191595,\n",
      "           0.02179226,  0.0327726 , -0.01520108,  0.05763172,\n",
      "          -0.0703341 ,  0.06126183,  0.0395813 , -0.01354232,\n",
      "           0.03576633, -0.00881837, -0.03451114,  0.0050294 ,\n",
      "           0.03301681,  0.00922726, -0.04383798,  0.05016236,\n",
      "           0.04231562,  0.07569602,  0.0421135 , -0.05143161,\n",
      "          -0.01372553, -0.02472955, -0.01192064,  0.02438935,\n",
      "          -0.05651937,  0.03748649,  0.07288532, -0.06885285,\n",
      "          -0.02611514, -0.00360711, -0.05304807, -0.00512908,\n",
      "           0.03835979,  0.00958976, -0.08044431,  0.06772999,\n",
      "          -0.01945662,  0.07532609,  0.03984983,  0.07628515,\n",
      "          -0.01140323,  0.0167182 , -0.00591543,  0.06539586,\n",
      "           0.07918239, -0.01431382,  0.0801602 ,  0.0025186 ,\n",
      "           0.03288785,  0.0469456 , -0.00723524,  0.00396527,\n",
      "          -0.08250801, -0.02264158,  0.06724551, -0.01078374,\n",
      "           0.08211707,  0.04579906,  0.07079296, -0.00874698,\n",
      "          -0.02352494, -0.07429001,  0.01575922,  0.03395035,\n",
      "           0.0293485 , -0.00204039, -0.06797528, -0.0369563 ,\n",
      "          -0.00447624, -0.03901383,  0.02895412,  0.08185795,\n",
      "          -0.02666654, -0.06117309,  0.00190678,  0.0402367 ,\n",
      "           0.06992905, -0.04099133,  0.01121631,  0.00971691,\n",
      "           0.07730202,  0.00369748,  0.07672668,  0.07018758,\n",
      "          -0.00324335, -0.0116134 ,  0.07156874,  0.07993321]],\n",
      "\n",
      "        [[-0.03289315,  0.07058401, -0.02906724,  0.04554035,\n",
      "          -0.04635439,  0.02448086, -0.0389993 ,  0.07456802,\n",
      "           0.06397493,  0.04894198, -0.08117066, -0.07005422,\n",
      "          -0.07982604,  0.06223318, -0.07057453, -0.04526486,\n",
      "          -0.04550289,  0.06501156,  0.078144  , -0.0558208 ,\n",
      "           0.01248471,  0.00325447, -0.0736454 ,  0.00252098,\n",
      "          -0.02685662,  0.06422386, -0.04159809,  0.05567229,\n",
      "           0.01392692,  0.07772355, -0.00651225, -0.00071982,\n",
      "           0.00873277, -0.03223498, -0.05943371, -0.07966053,\n",
      "          -0.03406829,  0.03968336,  0.0515781 , -0.04186815,\n",
      "          -0.07001783, -0.03161922,  0.00804655, -0.00466815,\n",
      "          -0.01876619,  0.0171615 ,  0.0724556 , -0.04469215,\n",
      "          -0.02749011, -0.00700674,  0.06752101, -0.00115915,\n",
      "           0.02352235, -0.03090687,  0.04659526,  0.03871586,\n",
      "           0.08043438, -0.07836688, -0.07867891,  0.08108228,\n",
      "          -0.02065321, -0.0632039 ,  0.01499854,  0.05391388,\n",
      "          -0.00995812, -0.01799218,  0.03721139, -0.07417524,\n",
      "          -0.06047248,  0.02634019, -0.02013224, -0.01033036,\n",
      "           0.02719697,  0.00199503, -0.07343735, -0.02717091,\n",
      "           0.01076856,  0.06935208, -0.0213045 , -0.05294624,\n",
      "          -0.04366355,  0.01588434, -0.00492761,  0.01192836,\n",
      "          -0.02215167, -0.03080479, -0.03529372,  0.05339968,\n",
      "           0.06130384,  0.07986639,  0.01948328,  0.07755277,\n",
      "           0.00660956,  0.07762843,  0.03601913, -0.06443069]],\n",
      "\n",
      "        [[-0.03439132,  0.04356769,  0.0338776 , -0.01856194,\n",
      "           0.04886383,  0.01181226, -0.00772127, -0.07425313,\n",
      "           0.06554185,  0.01845022,  0.06302623, -0.05607098,\n",
      "           0.05008826, -0.03994161, -0.0151856 , -0.03672194,\n",
      "           0.06336683,  0.03416838,  0.08207673,  0.08108608,\n",
      "           0.0170931 ,  0.06590641,  0.07537937, -0.03016251,\n",
      "           0.03423583,  0.07331194,  0.0606719 , -0.0275381 ,\n",
      "           0.02047275, -0.03167611,  0.00461523, -0.05679072,\n",
      "           0.07105258, -0.07455236, -0.01475456, -0.05902863,\n",
      "           0.03658164,  0.0431131 ,  0.0557088 ,  0.0305066 ,\n",
      "          -0.01718811,  0.06316926, -0.04382573,  0.02840804,\n",
      "           0.03304633, -0.07616396, -0.02390009,  0.03901669,\n",
      "           0.00856664,  0.0576954 , -0.00540678, -0.01776665,\n",
      "           0.03438327, -0.00610984,  0.08266708,  0.03022714,\n",
      "           0.0428078 ,  0.00486171, -0.00546063,  0.00442892,\n",
      "          -0.06897233,  0.02212673,  0.0739608 ,  0.05537707,\n",
      "           0.00995181, -0.05006282,  0.01189589, -0.03525723,\n",
      "           0.05123739,  0.07069089,  0.01123109, -0.05547125,\n",
      "          -0.02360183, -0.06144596, -0.05381039,  0.02182817,\n",
      "           0.06151327,  0.06443726,  0.036032  ,  0.01328855,\n",
      "          -0.05995777, -0.07810393,  0.03931776, -0.03672407,\n",
      "           0.07650757, -0.0089504 , -0.0038173 ,  0.06082731,\n",
      "           0.0173825 , -0.00557151,  0.02646922, -0.06093205,\n",
      "          -0.01396131,  0.05173536,  0.07585584,  0.01957159]]],\n",
      "\n",
      "\n",
      "       [[[ 0.00621256,  0.02901901,  0.07294174, -0.07548182,\n",
      "           0.04220074, -0.00075042, -0.01689945, -0.08043712,\n",
      "          -0.03587894,  0.00887413, -0.00742166,  0.03953002,\n",
      "          -0.04601589,  0.04635918, -0.01556141, -0.0197925 ,\n",
      "           0.01225653,  0.04043064,  0.07908668,  0.03138775,\n",
      "           0.0487604 , -0.08140952,  0.05290566,  0.06837811,\n",
      "           0.00566172, -0.01766414,  0.00821515,  0.03414803,\n",
      "          -0.07695413,  0.08170335, -0.0707959 , -0.02325516,\n",
      "          -0.01389027,  0.04391666,  0.0272295 , -0.03141106,\n",
      "           0.05895299,  0.07599992, -0.01597943,  0.00204609,\n",
      "           0.08280142,  0.0104706 ,  0.00177376, -0.05403726,\n",
      "           0.03702283, -0.07787537, -0.05658925, -0.05315933,\n",
      "          -0.03027015,  0.05292654,  0.07583143, -0.0566433 ,\n",
      "          -0.00027913,  0.00063574,  0.01574881, -0.0214484 ,\n",
      "          -0.02740405,  0.00620533,  0.06822668,  0.07727022,\n",
      "           0.03961964,  0.03554298, -0.01864366,  0.02738477,\n",
      "          -0.05407744, -0.05359131, -0.07062633,  0.03863767,\n",
      "          -0.06312574,  0.00226675,  0.08270502,  0.05814818,\n",
      "          -0.07913852, -0.05111273, -0.07392139, -0.0021949 ,\n",
      "          -0.06434575,  0.06618032, -0.05546346, -0.0163774 ,\n",
      "           0.08192226,  0.03669193,  0.08110815,  0.00904763,\n",
      "           0.05680665,  0.01676151, -0.03952188, -0.00673421,\n",
      "           0.06399056, -0.04815363, -0.03377677, -0.0640826 ,\n",
      "           0.05528843,  0.04189972,  0.04005978, -0.023788  ]],\n",
      "\n",
      "        [[ 0.07608306,  0.04306136,  0.03034714,  0.01965886,\n",
      "          -0.04048051,  0.02837082,  0.01893339, -0.02389371,\n",
      "           0.03957444,  0.05328111,  0.08152978, -0.03851921,\n",
      "          -0.0626223 , -0.01516686,  0.05770554,  0.04834628,\n",
      "           0.07142724, -0.01337823, -0.04604277,  0.08138697,\n",
      "          -0.06059054, -0.02924408, -0.04103312, -0.03900924,\n",
      "           0.01629672,  0.05880986,  0.04372163,  0.05437683,\n",
      "           0.0341863 , -0.05866338, -0.03643024,  0.01293176,\n",
      "           0.02715907,  0.02955626, -0.05094492,  0.05935396,\n",
      "           0.06389496, -0.07056771,  0.05810046,  0.001799  ,\n",
      "          -0.00455713, -0.06423216, -0.04526956,  0.05164306,\n",
      "          -0.03356637,  0.07401623, -0.01139307,  0.0374428 ,\n",
      "           0.01651853,  0.0666655 ,  0.05009581,  0.03692856,\n",
      "          -0.05572122,  0.08224083, -0.01444756, -0.03345462,\n",
      "           0.01721987, -0.01224386,  0.05382098,  0.04362582,\n",
      "          -0.00446488, -0.00202579, -0.07082545,  0.00267797,\n",
      "           0.06860267,  0.07910734, -0.00346893, -0.02420693,\n",
      "          -0.03641275, -0.00337856, -0.0220464 ,  0.05860086,\n",
      "           0.07381558,  0.05895796, -0.0333425 ,  0.07269527,\n",
      "          -0.07546573, -0.06329679,  0.01806629,  0.04768327,\n",
      "          -0.05571713, -0.00455435,  0.04032584, -0.05992934,\n",
      "           0.07336403, -0.04585171,  0.05853912, -0.02676528,\n",
      "          -0.00710285,  0.03952251,  0.00042344, -0.05872651,\n",
      "           0.02248777, -0.03987869,  0.01093631,  0.01815154]],\n",
      "\n",
      "        [[ 0.00844301, -0.03917557, -0.02828565, -0.07543555,\n",
      "           0.04647166,  0.01919907,  0.04337907, -0.03244137,\n",
      "          -0.07036301,  0.03934943, -0.0130906 , -0.00881367,\n",
      "           0.07816203,  0.01855873, -0.04589562,  0.06472796,\n",
      "           0.0212943 ,  0.03448062,  0.06023318, -0.00125444,\n",
      "           0.04682814, -0.07704189, -0.02079348, -0.0809871 ,\n",
      "           0.07025172,  0.06083302,  0.05640452,  0.06923778,\n",
      "          -0.03612614,  0.02169543, -0.00309953,  0.0307065 ,\n",
      "          -0.06324705, -0.00494029, -0.07318492, -0.02014843,\n",
      "          -0.04717348,  0.03638154, -0.01047561,  0.07603794,\n",
      "          -0.06579079, -0.06546301,  0.08071601, -0.01656076,\n",
      "          -0.03392565, -0.06094209,  0.04125115,  0.01803892,\n",
      "          -0.02765193,  0.00422635, -0.07701345,  0.06677   ,\n",
      "          -0.0754879 , -0.00806727, -0.02189243, -0.02357301,\n",
      "          -0.00617384,  0.05805828, -0.08260694, -0.02854994,\n",
      "          -0.05937468, -0.06149209,  0.03034194, -0.00353621,\n",
      "           0.07044995,  0.06332389,  0.06804396, -0.0542632 ,\n",
      "          -0.01781365,  0.00188778, -0.03404993, -0.05305517,\n",
      "          -0.05587956, -0.00514564, -0.02848497,  0.00401646,\n",
      "           0.04160084, -0.06721166, -0.01193473, -0.02938635,\n",
      "          -0.04764113,  0.05065165, -0.04046859,  0.03264761,\n",
      "          -0.02171074,  0.03440019, -0.03993259, -0.00610878,\n",
      "          -0.06099698, -0.00834785, -0.02192393,  0.07288134,\n",
      "           0.0103019 , -0.03332792, -0.05343261,  0.0248253 ]]]],\n",
      "      dtype=float32)>, <tf.Variable 'conv2d/bias:0' shape=(96,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'batch_normalization/gamma:0' shape=(96,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'batch_normalization/beta:0' shape=(96,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_1/kernel:0' shape=(1, 1, 96, 32) dtype=float32, numpy=\n",
      "array([[[[-0.10510492,  0.18341692,  0.03215547, ..., -0.03179614,\n",
      "           0.12075998, -0.15401143],\n",
      "         [-0.08866273, -0.19825253,  0.07279687, ...,  0.02817945,\n",
      "           0.15324022, -0.1893983 ],\n",
      "         [ 0.20804231,  0.02196451,  0.05988587, ...,  0.08806472,\n",
      "          -0.1254277 ,  0.20388494],\n",
      "         ...,\n",
      "         [-0.17928389,  0.05982156, -0.04375367, ..., -0.02973056,\n",
      "           0.17721222, -0.14593214],\n",
      "         [-0.00738634, -0.14003734,  0.14143704, ...,  0.17083932,\n",
      "           0.1433786 ,  0.12174274],\n",
      "         [-0.17792419, -0.08302024,  0.04268949, ..., -0.04260163,\n",
      "          -0.14872175,  0.10148193]]]], dtype=float32)>, <tf.Variable 'conv2d_1/bias:0' shape=(32,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>, <tf.Variable 'conv2d_2/kernel:0' shape=(3, 3, 96, 32) dtype=float32, numpy=\n",
      "array([[[[-0.03503497,  0.06113897,  0.01071849, ..., -0.01059872,\n",
      "           0.04025333, -0.05133714],\n",
      "         [-0.02955424, -0.06608418,  0.02426562, ...,  0.00939315,\n",
      "           0.05108008, -0.06313276],\n",
      "         [ 0.06934744,  0.00732151,  0.01996196, ...,  0.02935491,\n",
      "          -0.04180923,  0.06796165],\n",
      "         ...,\n",
      "         [-0.0597613 ,  0.01994053, -0.01458456, ..., -0.00991018,\n",
      "           0.05907074, -0.04864405],\n",
      "         [-0.00246211, -0.04667912,  0.04714569, ...,  0.05694644,\n",
      "           0.04779287,  0.04058091],\n",
      "         [-0.05930806, -0.02767342,  0.01422983, ..., -0.01420055,\n",
      "          -0.04957392,  0.03382731]],\n",
      "\n",
      "        [[ 0.01895358,  0.03955235, -0.0245605 , ...,  0.05910967,\n",
      "           0.0409045 , -0.03149468],\n",
      "         [-0.03642109,  0.00589367, -0.01861407, ..., -0.04389368,\n",
      "          -0.07139154, -0.04850294],\n",
      "         [ 0.02197134,  0.06872517,  0.06470498, ...,  0.00917666,\n",
      "          -0.00332556, -0.02221908],\n",
      "         ...,\n",
      "         [ 0.00541408, -0.00172611, -0.01901479, ...,  0.00817607,\n",
      "          -0.0601912 , -0.02845705],\n",
      "         [-0.04892747, -0.03355091,  0.00974306, ...,  0.00508294,\n",
      "          -0.05036135, -0.00478253],\n",
      "         [-0.05798988, -0.05498344,  0.00946915, ..., -0.06266794,\n",
      "          -0.06143307,  0.00179335]],\n",
      "\n",
      "        [[ 0.01283628, -0.03270213, -0.01257724, ..., -0.05018395,\n",
      "          -0.07000771,  0.01245517],\n",
      "         [ 0.07087569, -0.01955968,  0.06531018, ..., -0.03528932,\n",
      "           0.04684258, -0.03810377],\n",
      "         [-0.02565867, -0.06115438, -0.05928864, ..., -0.03235248,\n",
      "           0.03460201,  0.07193744],\n",
      "         ...,\n",
      "         [ 0.03209992, -0.05679346,  0.00333164, ..., -0.02398599,\n",
      "           0.01960185, -0.025357  ],\n",
      "         [ 0.03231351, -0.01215385,  0.06537054, ..., -0.07204068,\n",
      "          -0.05628332, -0.00492777],\n",
      "         [ 0.06181085,  0.07162513, -0.00351146, ...,  0.0308897 ,\n",
      "          -0.01539897,  0.06406903]]],\n",
      "\n",
      "\n",
      "       [[[-0.02061651,  0.05265097,  0.06858778, ...,  0.00523332,\n",
      "           0.02617562,  0.00998237],\n",
      "         [ 0.06468864, -0.04282198,  0.01292054, ..., -0.0683356 ,\n",
      "          -0.0628911 , -0.04602063],\n",
      "         [-0.04750356, -0.00724152, -0.06033692, ...,  0.02435224,\n",
      "           0.06346861,  0.06654413],\n",
      "         ...,\n",
      "         [ 0.04849508, -0.00549718,  0.01521712, ..., -0.00997424,\n",
      "           0.05324152,  0.03108323],\n",
      "         [ 0.0580079 ,  0.04051208,  0.06071518, ...,  0.03191179,\n",
      "          -0.01183102, -0.02586134],\n",
      "         [-0.06678451, -0.02122656,  0.06635249, ...,  0.00446536,\n",
      "           0.03238301, -0.02277154]],\n",
      "\n",
      "        [[ 0.04127777, -0.0479644 ,  0.01299021, ..., -0.06175712,\n",
      "           0.05382831,  0.01468776],\n",
      "         [-0.00732935, -0.02209688,  0.06684636, ...,  0.04306636,\n",
      "           0.01094499,  0.03390722],\n",
      "         [-0.01829373,  0.02315767, -0.01486762, ..., -0.02048022,\n",
      "           0.07002568,  0.06285837],\n",
      "         ...,\n",
      "         [ 0.03734396,  0.01298858, -0.00773084, ...,  0.0564687 ,\n",
      "          -0.00942065,  0.04734857],\n",
      "         [ 0.01877002,  0.00144359,  0.06226949, ...,  0.05722068,\n",
      "          -0.01468814,  0.06792311],\n",
      "         [-0.02962386, -0.03094056, -0.03904181, ..., -0.01668731,\n",
      "          -0.00285743, -0.02570991]],\n",
      "\n",
      "        [[-0.05056631,  0.05226953, -0.00781992, ...,  0.04557612,\n",
      "          -0.00755162, -0.04901409],\n",
      "         [ 0.02916287,  0.04666289,  0.0246082 , ...,  0.05920114,\n",
      "           0.04435483, -0.06842189],\n",
      "         [-0.0212384 ,  0.02495071, -0.03039102, ..., -0.04196467,\n",
      "          -0.01855183, -0.02126566],\n",
      "         ...,\n",
      "         [ 0.0181943 , -0.00379631,  0.01226564, ..., -0.00061862,\n",
      "          -0.022156  , -0.00856076],\n",
      "         [-0.0718594 ,  0.00420527, -0.02311355, ...,  0.03233109,\n",
      "           0.04514839, -0.03495565],\n",
      "         [ 0.00514723, -0.01991575, -0.00114875, ...,  0.05132806,\n",
      "          -0.06689026,  0.022827  ]]],\n",
      "\n",
      "\n",
      "       [[[-0.0511313 , -0.06014954,  0.03849084, ..., -0.04694335,\n",
      "          -0.0333168 , -0.02021954],\n",
      "         [-0.07080016,  0.00159191, -0.05964464, ..., -0.06301955,\n",
      "          -0.00461188, -0.05981551],\n",
      "         [ 0.01008851,  0.05632947, -0.0241221 , ...,  0.03002759,\n",
      "           0.06362168,  0.03464544],\n",
      "         ...,\n",
      "         [ 0.05934364,  0.03551359, -0.0287714 , ..., -0.05242107,\n",
      "          -0.0263049 , -0.05169443],\n",
      "         [ 0.017203  ,  0.04300151,  0.01439857, ..., -0.05725746,\n",
      "          -0.04863732, -0.05328234],\n",
      "         [-0.02085683,  0.00224447,  0.03027429, ...,  0.00775134,\n",
      "           0.04911545,  0.0189923 ]],\n",
      "\n",
      "        [[ 0.04015706, -0.06190717, -0.02000741, ...,  0.04064403,\n",
      "           0.00698441, -0.06320724],\n",
      "         [-0.06025187,  0.02513492,  0.01428752, ..., -0.00686705,\n",
      "          -0.04151708, -0.05318888],\n",
      "         [ 0.05083719,  0.02568702,  0.05221162, ...,  0.06103872,\n",
      "           0.02912723, -0.04187139],\n",
      "         ...,\n",
      "         [-0.03323959, -0.06727572, -0.02902783, ..., -0.05030686,\n",
      "          -0.03175456,  0.06186038],\n",
      "         [-0.03415237,  0.03959561, -0.02327892, ...,  0.04924463,\n",
      "           0.05769247, -0.02638146],\n",
      "         [ 0.04110628,  0.03334042, -0.05803116, ...,  0.02632444,\n",
      "          -0.04896722, -0.02310865]],\n",
      "\n",
      "        [[ 0.01844949,  0.0720315 ,  0.02938851, ...,  0.03193552,\n",
      "          -0.02288001, -0.03166371],\n",
      "         [-0.00155279,  0.03710969, -0.00547519, ...,  0.06814016,\n",
      "           0.06339568,  0.06119955],\n",
      "         [ 0.01812181,  0.04604329,  0.01689897, ..., -0.01046712,\n",
      "           0.06022421,  0.03911643],\n",
      "         ...,\n",
      "         [ 0.06284413,  0.07014211, -0.07066958, ..., -0.0594226 ,\n",
      "          -0.05642565,  0.0284531 ],\n",
      "         [-0.05982405,  0.01808526,  0.03660074, ...,  0.05480099,\n",
      "          -0.05288805, -0.01547884],\n",
      "         [ 0.06456715, -0.05824063,  0.05949195, ..., -0.04431017,\n",
      "           0.06031969, -0.04550919]]]], dtype=float32)>, <tf.Variable 'conv2d_2/bias:0' shape=(32,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>, <tf.Variable 'batch_normalization_1/gamma:0' shape=(32,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "      dtype=float32)>, <tf.Variable 'batch_normalization_1/beta:0' shape=(32,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>, <tf.Variable 'batch_normalization_2/gamma:0' shape=(32,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "      dtype=float32)>, <tf.Variable 'batch_normalization_2/beta:0' shape=(32,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>, <tf.Variable 'conv2d_3/kernel:0' shape=(1, 1, 64, 32) dtype=float32, numpy=\n",
      "array([[[[-0.12136471,  0.21179163,  0.03712994, ..., -0.03671503,\n",
      "           0.13944161, -0.17783707],\n",
      "         [-0.1023789 , -0.22892231,  0.08405858, ...,  0.03253883,\n",
      "           0.17694658, -0.21869832],\n",
      "         [ 0.24022657,  0.02536243,  0.06915027, ...,  0.10168839,\n",
      "          -0.14483142,  0.23542607],\n",
      "         ...,\n",
      "         [ 0.06788993,  0.2370289 ,  0.08350837, ..., -0.23401427,\n",
      "           0.03756595, -0.00328732],\n",
      "         [ 0.10823733,  0.14265507,  0.04382354, ...,  0.01517785,\n",
      "          -0.17089295, -0.21983653],\n",
      "         [-0.22894251,  0.15640318,  0.19383317, ...,  0.08187377,\n",
      "           0.14697099, -0.05032057]]]], dtype=float32)>, <tf.Variable 'conv2d_3/bias:0' shape=(32,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>, <tf.Variable 'conv2d_4/kernel:0' shape=(3, 3, 64, 48) dtype=float32, numpy=\n",
      "array([[[[-0.03745396,  0.06536032,  0.01145855, ..., -0.00081632,\n",
      "           0.02334058, -0.0163633 ],\n",
      "         [ 0.04753213, -0.05423331,  0.04357744, ...,  0.03138172,\n",
      "          -0.04469595,  0.07265406],\n",
      "         [ 0.00070512,  0.06215938,  0.00761813, ...,  0.04517183,\n",
      "          -0.07678022, -0.00150555],\n",
      "         ...,\n",
      "         [ 0.01651044,  0.04672728, -0.05727374, ..., -0.04646258,\n",
      "          -0.03384776,  0.02408139],\n",
      "         [-0.06388752,  0.02131732, -0.01559155, ..., -0.04577169,\n",
      "           0.07085984,  0.0317158 ],\n",
      "         [ 0.03102226, -0.02914834, -0.00904392, ..., -0.01518102,\n",
      "          -0.05299675,  0.03616292]],\n",
      "\n",
      "        [[ 0.02026223,  0.04228324, -0.02625629, ..., -0.04418661,\n",
      "           0.03275511, -0.05292108],\n",
      "         [-0.01952719, -0.07378254, -0.05884622, ...,  0.00981026,\n",
      "          -0.00355518, -0.0237532 ],\n",
      "         [ 0.04275249,  0.06995951,  0.02124713, ..., -0.01687303,\n",
      "          -0.00441162,  0.01162827],\n",
      "         ...,\n",
      "         [-0.06839297,  0.00098546,  0.04511481, ...,  0.02146112,\n",
      "          -0.0441743 , -0.07691724],\n",
      "         [ 0.00578789, -0.00184529, -0.02032766, ..., -0.00522757,\n",
      "           0.05732455, -0.04148129],\n",
      "         [ 0.07488295,  0.0108311 ,  0.04302689, ..., -0.06699485,\n",
      "          -0.06567471,  0.00191718]],\n",
      "\n",
      "        [[ 0.01372257, -0.03496005, -0.01344564, ...,  0.03856212,\n",
      "           0.0317373 ,  0.05629871],\n",
      "         [-0.037839  , -0.03928643,  0.04810136, ..., -0.03458626,\n",
      "           0.0369911 ,  0.07690436],\n",
      "         [ 0.02677006, -0.0765949 , -0.03879738, ...,  0.06710514,\n",
      "           0.06902345, -0.02599107],\n",
      "         ...,\n",
      "         [-0.03095124,  0.06735753,  0.01258099, ...,  0.02466756,\n",
      "           0.0497966 , -0.030857  ],\n",
      "         [ 0.03431627, -0.06071476,  0.00356167, ..., -0.07118402,\n",
      "          -0.01808408,  0.07458708],\n",
      "         [ 0.04685179,  0.05006082,  0.06429221, ...,  0.03302248,\n",
      "          -0.01646219,  0.06849269]]],\n",
      "\n",
      "\n",
      "       [[[-0.02203998,  0.05628625,  0.07332342, ...,  0.03961308,\n",
      "           0.03810413, -0.04919976],\n",
      "         [-0.01578292, -0.04477286, -0.03762148, ...,  0.02603364,\n",
      "           0.06785079,  0.07113869],\n",
      "         [-0.02553182,  0.02471092, -0.06182871, ..., -0.02391177,\n",
      "           0.01441567, -0.02935396],\n",
      "         ...,\n",
      "         [-0.00202773, -0.06154363,  0.01677593, ..., -0.01962584,\n",
      "          -0.04323919, -0.0448636 ],\n",
      "         [ 0.05184343, -0.00587673,  0.01626778, ...,  0.05267566,\n",
      "          -0.07606194,  0.07409664],\n",
      "         [-0.04194438, -0.02940493, -0.05164425, ...,  0.00477368,\n",
      "           0.03461889, -0.0243438 ]],\n",
      "\n",
      "        [[ 0.0441278 , -0.0512761 ,  0.01388712, ..., -0.076113  ,\n",
      "           0.01474616, -0.00516226],\n",
      "         [-0.06825096,  0.01501851, -0.02198608, ..., -0.02189428,\n",
      "           0.0748606 ,  0.06719843],\n",
      "         [-0.06706977,  0.00844742, -0.0745188 , ..., -0.05693554,\n",
      "          -0.03792311,  0.01325075],\n",
      "         ...,\n",
      "         [ 0.07040552, -0.05390694,  0.045517  , ...,  0.03021884,\n",
      "           0.02132197,  0.06939804],\n",
      "         [ 0.03992238,  0.01388538, -0.00826462, ...,  0.05583663,\n",
      "          -0.03800365,  0.02695499],\n",
      "         [-0.02907951,  0.07058478, -0.01327823, ..., -0.01783949,\n",
      "          -0.00305472, -0.02748505]],\n",
      "\n",
      "        [[-0.05405767,  0.05587848, -0.00835985, ...,  0.05448838,\n",
      "           0.02154322, -0.03091647],\n",
      "         [-0.01397428,  0.05463982,  0.01836879, ..., -0.04486213,\n",
      "          -0.01983274, -0.02273395],\n",
      "         [-0.04500667,  0.04116049,  0.02316818, ..., -0.00874547,\n",
      "          -0.04935304, -0.05728638],\n",
      "         ...,\n",
      "         [-0.04145509, -0.04004171,  0.05883611, ..., -0.01633902,\n",
      "           0.0467625 ,  0.00149363],\n",
      "         [ 0.01945052, -0.00405843,  0.01311252, ..., -0.06996348,\n",
      "           0.02180475,  0.04338917],\n",
      "         [ 0.06006021,  0.01063864,  0.07335704, ...,  0.054872  ,\n",
      "          -0.0715087 ,  0.02440309]]],\n",
      "\n",
      "\n",
      "       [[[-0.05466166, -0.06430257,  0.04114844, ..., -0.00626188,\n",
      "           0.04037389, -0.02423794],\n",
      "         [ 0.02399131,  0.05017824,  0.05901859, ...,  0.03210085,\n",
      "           0.06801445,  0.03703754],\n",
      "         [ 0.04323678, -0.04904228, -0.02609098, ...,  0.07675622,\n",
      "          -0.02194056, -0.03269212],\n",
      "         ...,\n",
      "         [-0.06541765,  0.06531244, -0.03946015, ...,  0.06537808,\n",
      "          -0.00983211, -0.02699554],\n",
      "         [ 0.06344102,  0.03796563, -0.03075793, ..., -0.06871229,\n",
      "          -0.07605454, -0.01738101],\n",
      "         [ 0.0168184 ,  0.01268707,  0.04047052, ...,  0.00828653,\n",
      "           0.05250663,  0.02030362]],\n",
      "\n",
      "        [[ 0.0429297 , -0.06618156, -0.02138882, ...,  0.00240105,\n",
      "           0.01906172, -0.02274082],\n",
      "         [-0.00712553,  0.02358808, -0.0129255 , ...,  0.06525313,\n",
      "           0.03113832, -0.04476241],\n",
      "         [ 0.06354327, -0.06447136, -0.01748229, ...,  0.066903  ,\n",
      "           0.02496348,  0.03047403],\n",
      "         ...,\n",
      "         [-0.02941975,  0.03175077,  0.06828538, ..., -0.06885161,\n",
      "           0.0551227 ,  0.07131129],\n",
      "         [-0.03553462, -0.07192077, -0.03103206, ...,  0.01943561,\n",
      "           0.03823825,  0.04827038],\n",
      "         [ 0.06064305, -0.07427323,  0.05964903, ...,  0.02814201,\n",
      "          -0.05234816, -0.02470418]],\n",
      "\n",
      "        [[ 0.01972333,  0.07700492,  0.03141765, ..., -0.06236349,\n",
      "           0.07650679,  0.04769459],\n",
      "         [-0.06872622, -0.07377011,  0.04292201, ..., -0.01118983,\n",
      "           0.06438238,  0.04181723],\n",
      "         [-0.03083454, -0.02091124, -0.01854606, ..., -0.04457885,\n",
      "          -0.07634889,  0.06289514],\n",
      "         ...,\n",
      "         [ 0.07019512, -0.06840353,  0.06785617, ..., -0.02479161,\n",
      "          -0.00527751, -0.05012016],\n",
      "         [ 0.0671832 ,  0.07498508, -0.07554895, ..., -0.01467036,\n",
      "          -0.01363779,  0.02602253],\n",
      "         [-0.02356811, -0.0423127 ,  0.02061105, ..., -0.04736957,\n",
      "           0.06448447, -0.04865137]]]], dtype=float32)>, <tf.Variable 'conv2d_4/bias:0' shape=(48,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>, <tf.Variable 'batch_normalization_3/gamma:0' shape=(32,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "      dtype=float32)>, <tf.Variable 'batch_normalization_3/beta:0' shape=(32,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>, <tf.Variable 'batch_normalization_4/gamma:0' shape=(48,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "      dtype=float32)>, <tf.Variable 'batch_normalization_4/beta:0' shape=(48,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>, <tf.Variable 'conv2d_5/kernel:0' shape=(3, 3, 80, 80) dtype=float32, numpy=\n",
      "array([[[[-0.03133623,  0.05468436,  0.00958691, ..., -0.00542596,\n",
      "           0.01795898,  0.04366512],\n",
      "         [-0.02585746,  0.012003  , -0.01783342, ..., -0.02241441,\n",
      "          -0.03170879,  0.05338263],\n",
      "         [-0.04935429, -0.01461133,  0.05765141, ..., -0.03877949,\n",
      "          -0.00269195,  0.01870914],\n",
      "         ...,\n",
      "         [-0.04381748,  0.03670719, -0.03791469, ..., -0.02893694,\n",
      "           0.03094898,  0.0643428 ],\n",
      "         [ 0.02239744, -0.06408389, -0.03246022, ..., -0.02866137,\n",
      "           0.00377288,  0.00367758],\n",
      "         [ 0.02748475,  0.05868129, -0.05202143, ..., -0.04485191,\n",
      "           0.0261746 ,  0.02116106]],\n",
      "\n",
      "        [[-0.00535961,  0.015582  , -0.02832609, ..., -0.03265099,\n",
      "           0.02169537, -0.02329628],\n",
      "         [ 0.04656065,  0.06074511, -0.05207802, ...,  0.01851588,\n",
      "           0.01266837,  0.04684739],\n",
      "         [ 0.03546999, -0.05925414, -0.0081024 , ...,  0.01322193,\n",
      "          -0.0114463 , -0.05619552],\n",
      "         ...,\n",
      "         [ 0.02561273, -0.02749345,  0.03448904, ...,  0.02965945,\n",
      "           0.00501271, -0.01259706],\n",
      "         [-0.03657089, -0.02238026, -0.00545676, ...,  0.01212759,\n",
      "          -0.03444189,  0.05798421],\n",
      "         [-0.00645595,  0.01664665,  0.02112359, ..., -0.04385687,\n",
      "          -0.00213834,  0.05752552]],\n",
      "\n",
      "        [[ 0.04133484,  0.03696155,  0.05991498, ..., -0.00483945,\n",
      "           0.00781938, -0.05904203],\n",
      "         [-0.02749924, -0.05661556,  0.05356827, ...,  0.02532456,\n",
      "           0.00099581, -0.01354202],\n",
      "         [ 0.01689868, -0.05500212, -0.02074138, ...,  0.02892158,\n",
      "          -0.03697694, -0.0425125 ],\n",
      "         ...,\n",
      "         [-0.02511005, -0.04744987, -0.03242747, ...,  0.01749732,\n",
      "          -0.0570365 ,  0.03308715],\n",
      "         [-0.00691689, -0.04061145,  0.0240741 , ..., -0.05747264,\n",
      "           0.05555616,  0.05244197],\n",
      "         [ 0.01687691, -0.04353617,  0.06307375, ...,  0.00186914,\n",
      "          -0.00403063, -0.02547378]]],\n",
      "\n",
      "\n",
      "       [[[-0.02071546, -0.0603653 , -0.01813651, ...,  0.05517703,\n",
      "           0.05446064, -0.04086205],\n",
      "         [ 0.04774214,  0.02307229, -0.0505643 , ..., -0.03962737,\n",
      "          -0.03275388, -0.01387786],\n",
      "         [ 0.0575384 , -0.02871445, -0.0176643 , ...,  0.05892471,\n",
      "           0.04081535, -0.04101091],\n",
      "         ...,\n",
      "         [ 0.02275342, -0.00155652,  0.00690332, ...,  0.00366075,\n",
      "          -0.00135777,  0.02007616],\n",
      "         [ 0.03643031, -0.01124932,  0.0315464 , ...,  0.05542206,\n",
      "          -0.01215437, -0.0371687 ],\n",
      "         [ 0.05196128, -0.03548569,  0.03874972, ...,  0.03084821,\n",
      "           0.06286088, -0.02609288]],\n",
      "\n",
      "        [[-0.05690284, -0.03594965,  0.04726154, ..., -0.01002299,\n",
      "          -0.01040339, -0.01939637],\n",
      "         [ 0.0427216 ,  0.00136022,  0.02274174, ...,  0.01051555,\n",
      "           0.03495593,  0.02229059],\n",
      "         [ 0.00843487,  0.02737347,  0.00387453, ..., -0.05102155,\n",
      "          -0.03958484,  0.02294888],\n",
      "         ...,\n",
      "         [-0.04795215, -0.05580575, -0.05830554, ..., -0.03166684,\n",
      "           0.05941801,  0.04672436],\n",
      "         [-0.00112249,  0.00123177, -0.02129203, ...,  0.06371126,\n",
      "           0.0239867 , -0.00447403],\n",
      "         [-0.02782599,  0.04222894,  0.02746826, ..., -0.02220679,\n",
      "          -0.05934263,  0.06065976]],\n",
      "\n",
      "        [[ 0.02782337,  0.02142931, -0.05688725, ...,  0.05125161,\n",
      "          -0.01880853, -0.05790278],\n",
      "         [ 0.0306346 , -0.05288746,  0.03516003, ...,  0.01746351,\n",
      "          -0.06216956,  0.06360772],\n",
      "         [-0.03602482, -0.04341293,  0.01025803, ...,  0.03932571,\n",
      "           0.02581348,  0.02381352],\n",
      "         ...,\n",
      "         [-0.04715377, -0.04796303,  0.04798347, ..., -0.06448668,\n",
      "           0.04138822, -0.05197523],\n",
      "         [ 0.0308336 , -0.01492043,  0.02045972, ...,  0.05395647,\n",
      "          -0.04377051,  0.05443513],\n",
      "         [ 0.05721693,  0.02320252, -0.0153098 , ...,  0.00797538,\n",
      "           0.00675382, -0.04166627]]],\n",
      "\n",
      "\n",
      "       [[[-0.0338771 ,  0.02993268,  0.05342109, ...,  0.05284934,\n",
      "          -0.05761807, -0.01898323],\n",
      "         [ 0.03082954,  0.00078082,  0.03436468, ...,  0.0016535 ,\n",
      "          -0.01201041,  0.05523969],\n",
      "         [ 0.00715867,  0.0030125 , -0.0013536 , ...,  0.02369029,\n",
      "           0.03630131,  0.01427905],\n",
      "         ...,\n",
      "         [ 0.00230601, -0.02296108,  0.01311359, ..., -0.05101883,\n",
      "          -0.03633681, -0.04825967],\n",
      "         [-0.02059784,  0.00438318, -0.00616978, ..., -0.04873987,\n",
      "          -0.0083068 ,  0.01725889],\n",
      "         [ 0.01992823, -0.00725688, -0.02327509, ...,  0.04853597,\n",
      "          -0.02509138,  0.01258153]],\n",
      "\n",
      "        [[-0.05129667,  0.01799195,  0.03740238, ..., -0.0482209 ,\n",
      "          -0.03877955,  0.0080407 ],\n",
      "         [ 0.02170765, -0.04656672, -0.06367835, ..., -0.01592207,\n",
      "           0.02343601,  0.02668788],\n",
      "         [ 0.0129171 ,  0.02380382, -0.02536965, ...,  0.01607346,\n",
      "          -0.04935641, -0.01643627],\n",
      "         ...,\n",
      "         [-0.03814323,  0.05438156, -0.00741706, ..., -0.06117451,\n",
      "          -0.00626824, -0.0382261 ],\n",
      "         [ 0.04900493,  0.05228876, -0.03121686, ..., -0.04503896,\n",
      "           0.03392375,  0.01268014],\n",
      "         [-0.01501429, -0.01889304, -0.05077481, ..., -0.02834361,\n",
      "          -0.0483891 , -0.02436138]],\n",
      "\n",
      "        [[ 0.0556888 ,  0.00459576,  0.06026522, ..., -0.02069681,\n",
      "          -0.03571297, -0.00578852],\n",
      "         [-0.00963954, -0.04440343, -0.05345196, ...,  0.00032172,\n",
      "           0.06182136,  0.01292086],\n",
      "         [-0.0229264 ,  0.0516438 , -0.0296166 , ...,  0.01447637,\n",
      "          -0.00768791,  0.05797895],\n",
      "         ...,\n",
      "         [-0.02863508, -0.05393977, -0.06422137, ..., -0.03876323,\n",
      "           0.05901483, -0.04919631],\n",
      "         [-0.04110916, -0.0316137 , -0.00861578, ...,  0.01325624,\n",
      "          -0.02300657,  0.0488975 ],\n",
      "         [ 0.03932063, -0.03419831,  0.02154795, ...,  0.03260975,\n",
      "           0.04225521,  0.06034541]]]], dtype=float32)>, <tf.Variable 'conv2d_5/bias:0' shape=(80,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'batch_normalization_5/gamma:0' shape=(80,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'batch_normalization_5/beta:0' shape=(80,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_6/kernel:0' shape=(1, 1, 160, 112) dtype=float32, numpy=\n",
      "array([[[[-0.07210138,  0.12582299,  0.02205847, ..., -0.05024868,\n",
      "           0.04989058, -0.09197369],\n",
      "         [-0.0224597 ,  0.0494591 ,  0.0819463 , ...,  0.03441052,\n",
      "           0.08874935,  0.11975929],\n",
      "         [ 0.10088636,  0.07036206, -0.08237059, ...,  0.13494849,\n",
      "           0.07139194,  0.13666669],\n",
      "         ...,\n",
      "         [ 0.1132032 , -0.03446296,  0.10369122, ..., -0.0594309 ,\n",
      "           0.02023253, -0.14431499],\n",
      "         [ 0.10348845,  0.04393482,  0.03713655, ...,  0.02968998,\n",
      "          -0.14393355, -0.02620503],\n",
      "         [ 0.03074749,  0.02814202, -0.08058888, ..., -0.01963042,\n",
      "          -0.02305733, -0.08496632]]]], dtype=float32)>, <tf.Variable 'conv2d_6/bias:0' shape=(112,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_7/kernel:0' shape=(3, 3, 160, 48) dtype=float32, numpy=\n",
      "array([[[[-2.74836961e-02,  4.79613580e-02,  8.40827450e-03, ...,\n",
      "          -5.99019229e-04,  1.71272941e-02, -1.20073818e-02],\n",
      "         [ 3.48790400e-02, -3.97963673e-02,  3.19770984e-02, ...,\n",
      "           2.30278857e-02, -3.27978581e-02,  5.33135049e-02],\n",
      "         [ 5.17409295e-04,  4.56125177e-02,  5.59017807e-03, ...,\n",
      "           3.31470557e-02, -5.63412756e-02, -1.10476837e-03],\n",
      "         ...,\n",
      "         [ 1.12304501e-02, -2.33515464e-02,  2.09031664e-02, ...,\n",
      "          -4.59323861e-02,  2.87184902e-02,  2.16755010e-02],\n",
      "         [ 1.57856457e-02, -2.65136361e-04, -5.21985330e-02, ...,\n",
      "          -5.25849685e-03,  3.56832780e-02, -3.81612070e-02],\n",
      "         [-2.17691734e-02,  5.22871725e-02,  3.41100730e-02, ...,\n",
      "           4.96434979e-02,  3.10528912e-02,  2.34933160e-02]],\n",
      "\n",
      "        [[-1.10238902e-02, -3.69888693e-02, -2.53571048e-02, ...,\n",
      "           4.19601463e-02, -1.48082264e-02, -2.74355616e-02],\n",
      "         [-1.70006230e-03, -2.84776185e-02,  1.49953850e-02, ...,\n",
      "          -5.63982502e-03, -4.22120541e-02, -5.30749187e-02],\n",
      "         [ 5.04057445e-02,  5.05215116e-02, -3.26717198e-02, ...,\n",
      "          -4.97669876e-02, -1.52025782e-02, -1.28409378e-02],\n",
      "         ...,\n",
      "         [ 5.16635217e-02, -3.95568758e-02,  3.34003456e-02, ...,\n",
      "           2.21745707e-02,  1.56460516e-02,  5.09242378e-02],\n",
      "         [ 2.92950161e-02,  1.01890825e-02, -6.06457144e-03, ...,\n",
      "           4.09728773e-02, -2.78870501e-02,  1.97795592e-02],\n",
      "         [-2.13385262e-02,  5.17950691e-02, -9.74355638e-03, ...,\n",
      "          -1.30906068e-02, -2.24155188e-03, -2.01685131e-02]],\n",
      "\n",
      "        [[-3.96674797e-02,  4.10035960e-02, -6.13445044e-03, ...,\n",
      "           3.99835445e-02,  1.58083998e-02, -2.26864852e-02],\n",
      "         [-1.02543160e-02,  4.00946699e-02,  1.34790055e-02, ...,\n",
      "          -3.29197943e-02, -1.45532526e-02, -1.66821517e-02],\n",
      "         [-3.30258608e-02,  3.02035399e-02,  1.70007981e-02, ...,\n",
      "          -6.41741976e-03, -3.62152308e-02, -4.20367047e-02],\n",
      "         ...,\n",
      "         [-5.24187908e-02, -2.68067680e-02,  3.67285125e-02, ...,\n",
      "           9.44903865e-03,  3.48148085e-02, -5.40831909e-02],\n",
      "         [ 2.66122781e-02, -4.50467393e-02,  2.16429867e-02, ...,\n",
      "           3.19064781e-03, -3.33402939e-02,  3.21175270e-02],\n",
      "         [-1.98144652e-02, -3.21573466e-02, -2.07948647e-02, ...,\n",
      "           2.85526924e-02,  4.32233550e-02, -3.50764208e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 3.85164581e-02,  4.96413894e-02, -5.15315272e-02, ...,\n",
      "           1.93733312e-02,  9.28551331e-03, -2.47783177e-02],\n",
      "         [-1.21443830e-02,  4.86461408e-02,  4.24402095e-02, ...,\n",
      "           1.54511444e-02, -1.67881921e-02,  3.65158655e-02],\n",
      "         [-1.52288601e-02,  3.05021368e-02, -5.59969619e-02, ...,\n",
      "          -1.49773546e-02, -3.42942774e-02,  1.61596648e-02],\n",
      "         ...,\n",
      "         [ 3.83442603e-02, -4.89100665e-02, -3.05384882e-02, ...,\n",
      "           1.94492303e-02, -8.14558193e-03,  2.22812220e-03],\n",
      "         [-3.40416655e-02, -5.42923398e-02,  2.29704343e-02, ...,\n",
      "           4.07551341e-02, -2.75396928e-03, -4.27864268e-02],\n",
      "         [ 1.01134218e-02,  2.84279324e-02, -6.56193867e-03, ...,\n",
      "          -3.83009091e-02,  4.22106795e-02, -1.76433325e-02]],\n",
      "\n",
      "        [[ 4.26661633e-02,  1.92897022e-03, -3.40427160e-02, ...,\n",
      "          -1.28090978e-02,  2.99996398e-02,  1.33483447e-02],\n",
      "         [ 9.40287486e-03, -2.16379762e-02,  5.60267642e-03, ...,\n",
      "          -5.52593358e-02,  2.66227685e-02, -1.19383112e-02],\n",
      "         [ 3.63493823e-02,  3.89512964e-02, -3.95749249e-02, ...,\n",
      "           3.57973911e-02, -1.19955167e-02,  2.50856467e-02],\n",
      "         ...,\n",
      "         [-8.82870331e-03, -4.92665693e-02,  1.22176595e-02, ...,\n",
      "          -1.70281008e-02,  1.16505660e-02, -1.56541727e-02],\n",
      "         [ 4.17802744e-02,  2.83092745e-02, -1.15327910e-03, ...,\n",
      "           1.47293843e-02, -3.86652537e-02, -2.34806798e-02],\n",
      "         [-7.43759423e-03,  2.26152688e-03, -4.04645801e-02, ...,\n",
      "           6.99486956e-03,  5.92349097e-03, -3.65437381e-02]],\n",
      "\n",
      "        [[-2.97121815e-02,  2.62526982e-02,  4.68533970e-02, ...,\n",
      "           1.90611519e-02,  4.74764518e-02, -1.37994848e-02],\n",
      "         [-2.77753156e-02,  3.59828658e-02, -2.14609653e-02, ...,\n",
      "           2.61758827e-02,  5.27872406e-02,  5.29100858e-02],\n",
      "         [ 4.90273722e-02,  4.83111404e-02,  5.52895181e-02, ...,\n",
      "           7.05186650e-03,  2.39997357e-03,  1.67090259e-02],\n",
      "         ...,\n",
      "         [ 3.82196791e-02, -7.66680017e-03, -9.40801576e-03, ...,\n",
      "          -2.81052291e-03,  4.90006246e-02,  4.28388156e-02],\n",
      "         [ 3.44834849e-03,  8.17541406e-03, -2.81005166e-02, ...,\n",
      "          -1.11534446e-02, -2.67883968e-02,  5.10465764e-02],\n",
      "         [ 2.29872763e-03,  6.07269630e-03,  1.60216950e-02, ...,\n",
      "          -3.65427807e-02,  1.74828134e-02,  1.46067888e-03]]],\n",
      "\n",
      "\n",
      "       [[[-6.10060990e-04,  5.43590076e-02, -6.16071746e-03, ...,\n",
      "           4.91304956e-02, -3.00058518e-02,  6.11687824e-03],\n",
      "         [ 2.56320126e-02,  5.00134863e-02,  1.68641023e-02, ...,\n",
      "           4.04054187e-02,  5.10396846e-02, -9.24853981e-03],\n",
      "         [ 2.63977796e-03,  1.65119767e-04,  2.02772357e-02, ...,\n",
      "          -3.95161696e-02, -1.11047439e-02, -5.54892421e-02],\n",
      "         ...,\n",
      "         [-1.73532963e-03, -2.15242431e-03, -4.81367931e-02, ...,\n",
      "          -5.64674288e-02,  2.57004984e-02,  9.29476693e-03],\n",
      "         [ 1.20130889e-02,  7.32712820e-03, -5.36534339e-02, ...,\n",
      "           2.11833827e-02, -4.94050458e-02, -3.98641415e-02],\n",
      "         [-4.48101237e-02, -3.98999527e-02,  5.01703136e-02, ...,\n",
      "           1.05476193e-02,  3.55348624e-02, -5.04013449e-02]],\n",
      "\n",
      "        [[-4.40392122e-02, -2.00195909e-02,  2.02845149e-02, ...,\n",
      "           2.24621259e-02, -2.05661841e-02, -5.60911633e-02],\n",
      "         [ 4.28239889e-02,  3.62363122e-02,  4.91677634e-02, ...,\n",
      "          -2.63106693e-02, -3.79625596e-02, -7.63822719e-03],\n",
      "         [-3.33702341e-02, -3.27128470e-02, -5.45665324e-02, ...,\n",
      "          -4.19927575e-02, -3.45273018e-02,  3.12525742e-02],\n",
      "         ...,\n",
      "         [-3.13369371e-02,  2.05304101e-03,  2.77119130e-03, ...,\n",
      "          -4.05609384e-02, -1.77735835e-02, -3.22299227e-02],\n",
      "         [ 1.75134428e-02, -2.05230042e-02, -5.12923189e-02, ...,\n",
      "           4.59989719e-02, -4.17494588e-02, -4.69989404e-02],\n",
      "         [ 2.83943526e-02, -2.17374824e-02, -1.00078322e-02, ...,\n",
      "           4.10288684e-02, -1.90973952e-02,  3.83369364e-02]],\n",
      "\n",
      "        [[ 1.26749985e-02,  2.31257714e-02, -4.92520630e-05, ...,\n",
      "           3.77889238e-02,  2.50729546e-03, -3.41751054e-02],\n",
      "         [-4.15823683e-02,  2.00486071e-02,  2.20107324e-02, ...,\n",
      "           4.90152091e-03, -4.41409461e-02, -1.98728703e-02],\n",
      "         [ 4.21984605e-02, -1.56100243e-02,  2.05035545e-02, ...,\n",
      "          -4.91903871e-02, -5.22426292e-02, -3.93824317e-02],\n",
      "         ...,\n",
      "         [-2.42057703e-02,  4.80700545e-02, -4.13571745e-02, ...,\n",
      "           5.21610938e-02, -3.74678783e-02,  2.75849961e-02],\n",
      "         [-4.13274653e-02,  4.54634018e-02, -3.51486206e-02, ...,\n",
      "          -1.31856836e-02,  2.58386545e-02,  4.85694073e-02],\n",
      "         [ 1.89363770e-02, -5.55251203e-02,  1.07794292e-02, ...,\n",
      "          -2.84753516e-02, -3.19791064e-02, -9.48593765e-03]]]],\n",
      "      dtype=float32)>, <tf.Variable 'conv2d_7/bias:0' shape=(48,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>, <tf.Variable 'batch_normalization_6/gamma:0' shape=(112,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'batch_normalization_6/beta:0' shape=(112,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'batch_normalization_7/gamma:0' shape=(48,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "      dtype=float32)>, <tf.Variable 'batch_normalization_7/beta:0' shape=(48,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>, <tf.Variable 'conv2d_8/kernel:0' shape=(1, 1, 160, 96) dtype=float32, numpy=\n",
      "array([[[[-0.07432041,  0.12969537,  0.02273735, ...,  0.06227116,\n",
      "          -0.08869077,  0.14416845],\n",
      "         [ 0.00139916,  0.12334369,  0.01511675, ...,  0.0574154 ,\n",
      "          -0.01033701,  0.11838709],\n",
      "         [ 0.04529031, -0.07186726,  0.03140604, ...,  0.11100461,\n",
      "           0.04793851, -0.09263965],\n",
      "         ...,\n",
      "         [ 0.04388388,  0.14881699, -0.02783979, ..., -0.1250325 ,\n",
      "           0.14338858,  0.01660034],\n",
      "         [ 0.00764997, -0.12914604, -0.08182829, ...,  0.05996366,\n",
      "           0.04230948,  0.13770746],\n",
      "         [ 0.07921852,  0.02755293, -0.01639959, ..., -0.03539914,\n",
      "          -0.00606152, -0.05453896]]]], dtype=float32)>, <tf.Variable 'conv2d_8/bias:0' shape=(96,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_9/kernel:0' shape=(3, 3, 160, 64) dtype=float32, numpy=\n",
      "array([[[[-2.64839511e-02,  4.62167226e-02,  8.10242072e-03, ...,\n",
      "           7.10055605e-03,  3.86129133e-02, -4.77238894e-02],\n",
      "         [ 5.24217375e-02,  5.53453714e-03,  1.50898285e-02, ...,\n",
      "           1.05712749e-02,  1.71383806e-02,  2.91737877e-02],\n",
      "         [ 4.02673222e-02, -5.36793359e-02,  6.54082000e-03, ...,\n",
      "           2.04598792e-02, -3.68357822e-03,  4.21870388e-02],\n",
      "         ...,\n",
      "         [-1.42762251e-02, -1.58812888e-02, -2.91689336e-02, ...,\n",
      "          -9.69288871e-03,  2.26651318e-02, -2.85615679e-02],\n",
      "         [-1.06083192e-02,  1.56862400e-02, -7.31110573e-04, ...,\n",
      "           4.09478880e-02, -1.69444531e-02, -3.43585685e-02],\n",
      "         [ 1.62154995e-02, -4.72246073e-02,  1.24359168e-02, ...,\n",
      "           4.43350933e-02, -2.27810219e-02,  5.10778837e-02]],\n",
      "\n",
      "        [[-3.27715427e-02, -2.08849423e-02,  1.35093443e-02, ...,\n",
      "           1.62964575e-02,  2.03381889e-02, -1.12741366e-02],\n",
      "         [-5.55515289e-03,  5.29262014e-02, -5.34566082e-02, ...,\n",
      "           4.77136113e-02,  3.40298973e-02,  4.36481126e-02],\n",
      "         [-2.07171664e-02, -3.93438675e-02, -4.57123592e-02, ...,\n",
      "           4.75082062e-02, -4.73654345e-02,  1.31876580e-02],\n",
      "         ...,\n",
      "         [-2.78303642e-02, -2.34580375e-02, -2.08905861e-02, ...,\n",
      "          -4.96917143e-02,  2.93680243e-02, -1.80388726e-02],\n",
      "         [ 3.68883349e-02, -3.06330174e-02,  1.50565915e-02, ...,\n",
      "          -5.07922955e-02, -4.03651595e-03, -1.82933100e-02],\n",
      "         [-1.49887130e-02,  2.94710957e-02,  5.07356934e-02, ...,\n",
      "           1.89020298e-02,  2.38036551e-02, -2.18102708e-02]],\n",
      "\n",
      "        [[ 1.49928890e-02,  5.14694043e-02, -3.75927612e-02, ...,\n",
      "           3.04188095e-02,  3.49741168e-02, -5.32926172e-02],\n",
      "         [-5.14624454e-02,  4.23480235e-02,  1.37463696e-02, ...,\n",
      "           3.95525582e-02, -2.38052402e-02,  9.43863019e-03],\n",
      "         [ 4.69810404e-02,  3.29572670e-02, -1.07470155e-03, ...,\n",
      "          -2.20663212e-02,  4.19595204e-02, -1.74451768e-02],\n",
      "         ...,\n",
      "         [ 3.50712724e-02,  3.85498367e-02,  4.55541164e-03, ...,\n",
      "          -7.44078681e-03, -7.74865970e-03, -8.56017694e-03],\n",
      "         [-3.68856341e-02,  3.76892947e-02, -2.72587147e-02, ...,\n",
      "          -3.27204913e-02,  4.30158041e-02, -1.99033841e-02],\n",
      "         [ 3.50748040e-02, -4.39724699e-03, -4.01070267e-02, ...,\n",
      "          -3.69076803e-02,  4.06752266e-02, -1.70015395e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 4.11141403e-02,  1.85880065e-03, -3.28043848e-02, ...,\n",
      "          -1.46372281e-02, -5.25506847e-02,  4.16074805e-02],\n",
      "         [ 2.20193304e-02, -3.30170207e-02,  1.42855756e-02, ...,\n",
      "          -1.43645033e-02,  1.25934966e-02, -4.41626385e-02],\n",
      "         [ 2.19260938e-02,  4.36166488e-02, -2.93863937e-02, ...,\n",
      "          -2.18850859e-02, -2.30926387e-02,  4.94549088e-02],\n",
      "         ...,\n",
      "         [ 1.29201002e-02,  1.17974170e-02,  4.18501310e-02, ...,\n",
      "           7.08654523e-03, -2.12010965e-02,  3.84527706e-02],\n",
      "         [-4.43504043e-02,  5.88793308e-03,  1.75948702e-02, ...,\n",
      "           3.88216190e-02, -2.67193615e-02,  4.41438667e-02],\n",
      "         [-2.16191262e-03, -3.55608016e-02,  1.82999931e-02, ...,\n",
      "           4.87837605e-02,  1.89258792e-02, -8.00720602e-03]],\n",
      "\n",
      "        [[ 1.12088434e-02,  4.01544385e-02,  4.75839861e-02, ...,\n",
      "           7.61258230e-03,  5.26118018e-02, -3.57655138e-02],\n",
      "         [-3.65599841e-02, -1.05859861e-02, -5.41514196e-02, ...,\n",
      "          -2.63145640e-02,  5.35383038e-02, -1.95504837e-02],\n",
      "         [ 5.34502976e-02, -3.05271931e-02,  9.00175422e-04, ...,\n",
      "          -2.83377990e-02,  4.91121970e-02, -2.80620530e-03],\n",
      "         ...,\n",
      "         [-1.36705376e-02, -1.26006901e-02,  1.17517449e-02, ...,\n",
      "           1.38118304e-02, -1.88708380e-02,  1.15315951e-02],\n",
      "         [ 3.37089039e-02, -2.58342549e-03, -1.77806728e-02, ...,\n",
      "          -4.51339222e-02, -3.05920970e-02,  3.80726568e-02],\n",
      "         [ 5.06041534e-02, -3.47498655e-02,  5.21731339e-02, ...,\n",
      "          -2.39547286e-02, -4.08962518e-02, -2.05891281e-02]],\n",
      "\n",
      "        [[ 4.70656268e-02,  3.88412923e-03,  5.09334095e-02, ...,\n",
      "          -4.91463244e-02,  9.57767293e-03, -8.36248696e-03],\n",
      "         [-2.01614127e-02,  3.80876698e-02, -1.76406689e-02, ...,\n",
      "          -1.43088326e-02,  3.07212137e-02, -4.55936864e-02],\n",
      "         [ 5.10696806e-02, -7.09829107e-03, -4.54311147e-02, ...,\n",
      "           1.23078041e-02,  3.26313712e-02, -2.04510987e-03],\n",
      "         ...,\n",
      "         [ 4.27199118e-02,  3.19287442e-02,  1.10830404e-02, ...,\n",
      "          -3.34856287e-03,  2.09682398e-02,  2.78535448e-02],\n",
      "         [ 4.25086804e-02,  6.73325732e-03,  4.54655848e-02, ...,\n",
      "           8.72929022e-03, -5.20585217e-02, -4.90741245e-02],\n",
      "         [-1.05829425e-02, -3.90594080e-02, -3.04122400e-02, ...,\n",
      "           3.95364054e-02, -1.84027106e-02,  3.69423963e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 1.22139342e-02,  2.22845487e-02, -4.74601984e-05, ...,\n",
      "          -2.21504122e-02, -5.32566160e-02,  5.03001176e-02],\n",
      "         [-1.07463449e-04,  2.07832642e-02,  7.96865299e-03, ...,\n",
      "          -4.07131985e-02,  2.56949998e-02, -4.49107364e-02],\n",
      "         [ 8.52086022e-03,  1.98720135e-02,  1.83168016e-02, ...,\n",
      "          -2.24095322e-02,  3.26442458e-02,  5.25024422e-02],\n",
      "         ...,\n",
      "         [ 4.31241877e-02,  4.02587652e-03, -3.14569473e-02, ...,\n",
      "           1.93295740e-02,  6.01518899e-03, -5.09217381e-03],\n",
      "         [ 3.86594124e-02,  3.20780240e-02, -2.98571885e-02, ...,\n",
      "           3.00620683e-02,  2.46298574e-02, -2.39111558e-02],\n",
      "         [-2.68056616e-02,  2.05448531e-02, -7.51046464e-03, ...,\n",
      "          -3.30876485e-02,  4.71210480e-03, -3.32906581e-02]],\n",
      "\n",
      "        [[-1.64808631e-02, -4.09866497e-03, -3.02783344e-02, ...,\n",
      "          -3.19005698e-02, -6.63124397e-03,  2.82574557e-02],\n",
      "         [-7.95596093e-03, -1.91074982e-02,  4.11189534e-02, ...,\n",
      "          -2.42098942e-02, -1.84966438e-02, -4.48852852e-02],\n",
      "         [ 4.30092849e-02, -2.22069770e-02, -3.50132398e-02, ...,\n",
      "           3.30311172e-02, -1.25004351e-03, -8.47545266e-03],\n",
      "         ...,\n",
      "         [-1.73001513e-02, -2.04521790e-02, -9.26565379e-04, ...,\n",
      "           4.04792689e-02,  1.90251134e-02,  1.00882985e-02],\n",
      "         [ 2.45284550e-02,  1.88560076e-02,  3.74466665e-02, ...,\n",
      "           4.05958258e-02,  3.28711756e-02, -3.55972834e-02],\n",
      "         [-6.43290207e-03, -3.08008045e-02,  5.43986298e-02, ...,\n",
      "           4.28428538e-02, -1.98379196e-02, -3.56537178e-02]],\n",
      "\n",
      "        [[ 5.10069616e-02,  4.47699167e-02,  2.10101046e-02, ...,\n",
      "           6.35199249e-04, -2.79289167e-02,  8.64509493e-04],\n",
      "         [-2.32642628e-02,  5.22424616e-02,  2.93279402e-02, ...,\n",
      "           2.59835832e-02,  2.24764235e-02, -2.70810165e-02],\n",
      "         [-2.44636573e-02, -5.14723808e-02, -5.21111079e-02, ...,\n",
      "           5.28069176e-02, -4.47582714e-02,  2.71433331e-02],\n",
      "         ...,\n",
      "         [ 7.12782890e-03,  2.29610987e-02,  4.12554778e-02, ...,\n",
      "           4.05330025e-02, -3.60123590e-02, -5.44155985e-02],\n",
      "         [-5.00969514e-02,  1.34281404e-02,  2.35039778e-02, ...,\n",
      "          -2.09892169e-03, -2.04199106e-02, -1.38676688e-02],\n",
      "         [ 1.23273395e-02,  1.05968602e-02,  3.12358402e-02, ...,\n",
      "          -3.46515328e-04, -4.20226157e-02, -2.73769721e-03]]]],\n",
      "      dtype=float32)>, <tf.Variable 'conv2d_9/bias:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'batch_normalization_8/gamma:0' shape=(96,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'batch_normalization_8/beta:0' shape=(96,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'batch_normalization_9/gamma:0' shape=(64,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'batch_normalization_9/beta:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_10/kernel:0' shape=(1, 1, 160, 80) dtype=float32, numpy=\n",
      "array([[[[-0.07675778,  0.13394879,  0.02348304, ..., -0.01329082,\n",
      "           0.04399031,  0.10695727],\n",
      "         [-0.06333759,  0.02940124, -0.04368278, ..., -0.05490387,\n",
      "          -0.07767036,  0.13076021],\n",
      "         [-0.12089282, -0.03579029,  0.14121653, ..., -0.09498996,\n",
      "          -0.0065939 ,  0.04582784],\n",
      "         ...,\n",
      "         [ 0.06273812, -0.06734492,  0.08448057, ...,  0.07265051,\n",
      "           0.01227857, -0.03085636],\n",
      "         [-0.08958003, -0.05482022, -0.01336628, ...,  0.0297064 ,\n",
      "          -0.08436505,  0.14203171],\n",
      "         [-0.01581378,  0.04077581,  0.05174202, ..., -0.10742694,\n",
      "          -0.00523785,  0.14090817]]]], dtype=float32)>, <tf.Variable 'conv2d_10/bias:0' shape=(80,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_11/kernel:0' shape=(3, 3, 160, 80) dtype=float32, numpy=\n",
      "array([[[[-2.55859289e-02,  4.46495973e-02,  7.82767683e-03, ...,\n",
      "          -4.43027169e-03,  1.46634392e-02,  3.56524251e-02],\n",
      "         [-2.11125277e-02,  9.80041549e-03, -1.45609304e-02, ...,\n",
      "          -1.83012933e-02, -2.58901212e-02,  4.35867347e-02],\n",
      "         [-4.02976088e-02, -1.19300969e-02,  4.70721759e-02, ...,\n",
      "          -3.16633210e-02, -2.19796598e-03,  1.52759440e-02],\n",
      "         ...,\n",
      "         [ 2.09127106e-02, -2.24483069e-02,  2.81601883e-02, ...,\n",
      "           2.42168419e-02,  4.09285724e-03, -1.02854520e-02],\n",
      "         [-2.98600085e-02, -1.82734095e-02, -4.45542857e-03, ...,\n",
      "           9.90213826e-03, -2.81216875e-02,  4.73439135e-02],\n",
      "         [-5.27126342e-03,  1.35919340e-02,  1.72473378e-02, ...,\n",
      "          -3.58089805e-02, -1.74595043e-03,  4.69693877e-02]],\n",
      "\n",
      "        [[ 3.37497555e-02,  3.01789753e-02,  4.89203744e-02, ...,\n",
      "          -3.95139307e-03,  6.38449937e-03, -4.82076183e-02],\n",
      "         [-2.24530324e-02, -4.62264121e-02,  4.37383167e-02, ...,\n",
      "           2.06774138e-02,  8.13081861e-04, -1.10570155e-02],\n",
      "         [ 1.37977116e-02, -4.49090451e-02, -1.69352666e-02, ...,\n",
      "           2.36143731e-02, -3.01915444e-02, -3.47113088e-02],\n",
      "         ...,\n",
      "         [ 1.85780935e-02, -1.27089024e-03,  5.63653558e-03, ...,\n",
      "           2.98899412e-03, -1.10861287e-03,  1.63921155e-02],\n",
      "         [ 2.97452174e-02, -9.18503106e-03,  2.57575251e-02, ...,\n",
      "           4.52519245e-02, -9.92399827e-03, -3.03481128e-02],\n",
      "         [ 4.24262099e-02, -2.89739463e-02,  3.16390209e-02, ...,\n",
      "           2.51874588e-02,  5.13256975e-02, -2.13047490e-02]],\n",
      "\n",
      "        [[-4.64609787e-02, -2.93527674e-02,  3.85888927e-02, ...,\n",
      "          -8.18374008e-03, -8.49432871e-03, -1.58370696e-02],\n",
      "         [ 3.48820426e-02,  1.11061335e-03,  1.85685568e-02, ...,\n",
      "           8.58590752e-03,  2.85413973e-02,  1.82001851e-02],\n",
      "         [ 6.88704476e-03,  2.23503448e-02,  3.16354260e-03, ...,\n",
      "          -4.16589230e-02, -3.23208869e-02,  1.87376849e-02],\n",
      "         ...,\n",
      "         [-3.85008939e-02, -3.91616523e-02,  3.91783379e-02, ...,\n",
      "          -5.26531599e-02,  3.37933414e-02, -4.24375981e-02],\n",
      "         [ 2.51755305e-02, -1.21824816e-02,  1.67052858e-02, ...,\n",
      "           4.40552719e-02, -3.57384756e-02,  4.44460921e-02],\n",
      "         [ 4.67174314e-02,  1.89447813e-02, -1.25003941e-02, ...,\n",
      "           6.51186705e-03,  5.51447272e-03, -3.40203717e-02]]],\n",
      "\n",
      "\n",
      "       [[[-2.76605356e-02,  2.44399272e-02,  4.36181389e-02, ...,\n",
      "           4.31513079e-02, -4.70449589e-02, -1.54997408e-02],\n",
      "         [ 2.51722150e-02,  6.37535006e-04,  2.80586444e-02, ...,\n",
      "           1.35007873e-03, -9.80645791e-03,  4.51030172e-02],\n",
      "         [ 5.84502891e-03,  2.45969743e-03, -1.10520795e-03, ...,\n",
      "           1.93430446e-02,  2.96398960e-02,  1.16587915e-02],\n",
      "         ...,\n",
      "         [-3.11438162e-02,  4.44023572e-02, -6.05600700e-03, ...,\n",
      "          -4.99487817e-02, -5.11799753e-03, -3.12114824e-02],\n",
      "         [ 4.00123559e-02,  4.26935963e-02, -2.54884567e-02, ...,\n",
      "          -3.67741585e-02,  2.76986249e-02,  1.03532933e-02],\n",
      "         [-1.22591220e-02, -1.54261068e-02, -4.14574556e-02, ...,\n",
      "          -2.31424663e-02, -3.95095348e-02, -1.98909864e-02]],\n",
      "\n",
      "        [[ 4.54697125e-02,  3.75242531e-03,  4.92063425e-02, ...,\n",
      "          -1.68988779e-02, -2.91595180e-02, -4.72630933e-03],\n",
      "         [-7.87065178e-03, -3.62552553e-02, -4.36433442e-02, ...,\n",
      "           2.62688845e-04,  5.04769348e-02,  1.05498396e-02],\n",
      "         [-1.87193304e-02,  4.21669893e-02, -2.41818558e-02, ...,\n",
      "           1.18199103e-02, -6.27715141e-03,  4.73396145e-02],\n",
      "         ...,\n",
      "         [ 3.65354083e-02, -2.27702670e-02,  1.75460391e-02, ...,\n",
      "           3.99528556e-02, -4.32671010e-02, -4.49250378e-02],\n",
      "         [-5.78016043e-05,  2.17019133e-02, -1.38588287e-02, ...,\n",
      "          -4.81258780e-02, -3.80956382e-03,  2.19565444e-02],\n",
      "         [-1.80651434e-02,  3.50936502e-03,  5.77947125e-03, ...,\n",
      "          -3.91804501e-02,  4.96291183e-02, -3.71269286e-02]],\n",
      "\n",
      "        [[ 1.24448203e-02, -5.11181131e-02, -3.42927426e-02, ...,\n",
      "           1.67891383e-04, -4.13299724e-02, -3.88743356e-03],\n",
      "         [ 4.49153669e-02, -2.87739504e-02, -7.56451488e-03, ...,\n",
      "           3.15285809e-02, -4.16851938e-02,  2.12336518e-02],\n",
      "         [ 3.62343676e-02, -5.77204674e-03, -5.14339283e-02, ...,\n",
      "          -4.61962931e-02,  3.04885097e-02,  4.53151427e-02],\n",
      "         ...,\n",
      "         [-2.90572643e-07, -1.45904720e-02,  3.35181765e-02, ...,\n",
      "          -5.24672978e-02,  1.38653070e-03, -5.03092818e-02],\n",
      "         [ 4.81354259e-02,  7.67515600e-03,  1.28538907e-03, ...,\n",
      "          -4.26218361e-02, -1.64694563e-02,  4.16920222e-02],\n",
      "         [ 3.26234810e-02,  3.36461328e-02, -3.77687812e-03, ...,\n",
      "          -4.57898155e-02, -3.56604904e-02, -4.28385697e-02]]],\n",
      "\n",
      "\n",
      "       [[[-3.82311642e-04, -3.05322390e-02,  3.26808877e-02, ...,\n",
      "          -2.08272226e-02, -2.09981315e-02, -3.47230472e-02],\n",
      "         [-3.76181118e-02, -2.92872358e-02, -7.10693002e-03, ...,\n",
      "           4.57274541e-03, -2.49242652e-02, -1.77259818e-02],\n",
      "         [-3.25055420e-02, -1.32132247e-02, -6.05125725e-03, ...,\n",
      "           4.43051569e-02,  1.52194239e-02,  4.62863855e-02],\n",
      "         ...,\n",
      "         [-4.42906842e-02,  2.91971527e-02,  4.62548248e-02, ...,\n",
      "           5.20819686e-02, -2.75083650e-02,  4.49158885e-02],\n",
      "         [-4.95721847e-02,  7.41441548e-03,  4.16366383e-03, ...,\n",
      "           3.77484076e-02, -5.07398583e-02,  4.51546907e-03],\n",
      "         [-3.83498147e-02,  4.37994115e-02,  4.00509275e-02, ...,\n",
      "           1.46278329e-02, -3.88358720e-02, -2.29322035e-02]],\n",
      "\n",
      "        [[-1.31248757e-02, -1.09791197e-02, -2.63830498e-02, ...,\n",
      "          -2.23392379e-02,  2.45710202e-02, -7.64898211e-03],\n",
      "         [-4.26119566e-02,  2.46469788e-02,  3.43723260e-02, ...,\n",
      "           2.72498839e-02,  6.79943338e-03,  4.90340702e-02],\n",
      "         [ 1.44193880e-02,  5.16028367e-02,  3.31258662e-02, ...,\n",
      "           4.74668555e-02,  2.62336023e-02,  1.46935992e-02],\n",
      "         ...,\n",
      "         [ 3.09415795e-02,  3.06508504e-02, -3.92990336e-02, ...,\n",
      "          -2.71804985e-02,  4.72795591e-03, -1.42741017e-02],\n",
      "         [ 4.84437905e-02, -2.67228037e-02,  1.77631415e-02, ...,\n",
      "          -1.32158399e-02, -4.61070761e-02,  2.93799452e-02],\n",
      "         [ 4.95444052e-02,  4.62011807e-02,  4.91234846e-02, ...,\n",
      "           1.37678422e-02, -9.05539840e-04,  3.38359065e-02]],\n",
      "\n",
      "        [[ 4.99310158e-02, -5.79529256e-03, -4.27136160e-02, ...,\n",
      "           1.34466104e-02,  1.84902959e-02,  1.57530792e-02],\n",
      "         [ 2.04570256e-02,  8.55766237e-03, -6.21737540e-03, ...,\n",
      "           5.17316163e-03, -4.14191559e-03, -7.44554028e-03],\n",
      "         [ 4.71910723e-02, -3.21298130e-02, -3.39438319e-02, ...,\n",
      "           2.35214122e-02,  2.24982314e-02,  1.49632506e-02],\n",
      "         ...,\n",
      "         [-3.62888165e-02, -2.98074465e-02, -5.52289188e-04, ...,\n",
      "          -1.26930773e-02,  3.70295681e-02,  4.16528434e-04],\n",
      "         [ 1.40947662e-02, -2.58812364e-02, -4.82772663e-03, ...,\n",
      "           2.45059244e-02, -2.15464123e-02,  1.33428350e-03],\n",
      "         [ 4.59464379e-02, -1.97265632e-02, -2.05564685e-02, ...,\n",
      "           5.19348271e-02,  5.48133627e-03, -2.54740547e-02]]]],\n",
      "      dtype=float32)>, <tf.Variable 'conv2d_11/bias:0' shape=(80,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'batch_normalization_10/gamma:0' shape=(80,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'batch_normalization_10/beta:0' shape=(80,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'batch_normalization_11/gamma:0' shape=(80,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'batch_normalization_11/beta:0' shape=(80,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_12/kernel:0' shape=(1, 1, 160, 48) dtype=float32, numpy=\n",
      "array([[[[-0.08245109,  0.1438841 ,  0.02522482, ..., -0.00179705,\n",
      "           0.05138189, -0.03602214],\n",
      "         [ 0.10463712, -0.11938911,  0.09593129, ...,  0.06908366,\n",
      "          -0.09839357,  0.15994051],\n",
      "         [ 0.00155224,  0.13683754,  0.01677054, ...,  0.09944117,\n",
      "          -0.16902384, -0.0033143 ],\n",
      "         ...,\n",
      "         [ 0.03369135, -0.07005464,  0.06270951, ..., -0.13779716,\n",
      "           0.08615547,  0.06502651],\n",
      "         [ 0.04735693, -0.00079541, -0.1565956 , ..., -0.01577549,\n",
      "           0.10704985, -0.11448362],\n",
      "         [-0.06530753,  0.15686151,  0.10233021, ...,  0.14893049,\n",
      "           0.09315866,  0.07047994]]]], dtype=float32)>, <tf.Variable 'conv2d_12/bias:0' shape=(48,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>, <tf.Variable 'conv2d_13/kernel:0' shape=(3, 3, 160, 96) dtype=float32, numpy=\n",
      "array([[[[-2.47734692e-02,  4.32317853e-02,  7.57911801e-03, ...,\n",
      "           2.07570568e-02, -2.95635909e-02,  4.80561480e-02],\n",
      "         [ 4.66387719e-04,  4.11145687e-02,  5.03892079e-03, ...,\n",
      "           1.91384628e-02, -3.44567001e-03,  3.94623578e-02],\n",
      "         [ 1.50967687e-02, -2.39557549e-02,  1.04686841e-02, ...,\n",
      "           3.70015353e-02,  1.59794986e-02, -3.08798868e-02],\n",
      "         ...,\n",
      "         [ 1.46279559e-02,  4.96056676e-02, -9.27993283e-03, ...,\n",
      "          -4.16774973e-02,  4.77961898e-02,  5.53344935e-03],\n",
      "         [ 2.54999101e-03, -4.30486798e-02, -2.72760969e-02, ...,\n",
      "           1.99878886e-02,  1.41031593e-02,  4.59024832e-02],\n",
      "         [ 2.64061764e-02,  9.18431208e-03, -5.46653196e-03, ...,\n",
      "          -1.17997117e-02, -2.02050805e-03, -1.81796513e-02]],\n",
      "\n",
      "        [[-3.57557833e-02,  3.69601473e-02, -5.52951917e-03, ...,\n",
      "          -2.96735056e-02, -1.31181255e-02, -1.50370896e-02],\n",
      "         [-2.97691114e-02,  2.72251070e-02,  1.53243095e-02, ...,\n",
      "           2.85220668e-02, -1.43150166e-02, -3.27109694e-02],\n",
      "         [-1.90070868e-02, -4.82098237e-02,  4.47568893e-02, ...,\n",
      "           4.27495688e-03,  9.55320895e-03,  2.38460973e-02],\n",
      "         ...,\n",
      "         [-3.37347388e-03,  1.65662542e-03,  7.07747042e-03, ...,\n",
      "          -4.50344607e-02,  1.50311142e-02, -4.49789949e-02],\n",
      "         [ 3.28061730e-02,  3.60600725e-02,  4.26119566e-03, ...,\n",
      "           1.75312981e-02, -7.34232739e-03,  2.00840086e-03],\n",
      "         [-3.06847449e-02, -4.89384532e-02,  2.07052752e-02, ...,\n",
      "          -3.45239714e-02,  3.80481929e-02, -1.59034841e-02]],\n",
      "\n",
      "        [[ 3.84587571e-02,  1.73874944e-03, -3.06856930e-02, ...,\n",
      "          -4.98100929e-02,  2.39974409e-02, -1.07610486e-02],\n",
      "         [ 3.27648968e-02,  3.51102278e-02, -3.56723554e-02, ...,\n",
      "          -2.04716232e-02, -2.16011852e-02,  4.62608337e-02],\n",
      "         [-7.37116486e-03, -8.51027668e-04,  1.98353976e-02, ...,\n",
      "          -1.89560615e-02, -4.96572256e-03, -2.48700362e-02],\n",
      "         ...,\n",
      "         [-6.98806718e-03,  3.56681198e-02,  5.56230918e-03, ...,\n",
      "          -3.83782648e-02,  4.58652899e-02, -3.80124599e-02],\n",
      "         [-3.52166593e-04, -5.13958558e-03,  3.14489603e-02, ...,\n",
      "          -2.53337249e-03,  4.41685691e-02,  3.86143848e-02],\n",
      "         [ 3.10830027e-03,  7.36921653e-03, -2.53294650e-02, ...,\n",
      "          -3.29392180e-02,  1.57587975e-02,  1.31663680e-03]]],\n",
      "\n",
      "\n",
      "       [[[-5.49901277e-04,  4.89985496e-02, -5.55319712e-03, ...,\n",
      "           3.64209488e-02,  4.60065454e-02, -8.33652169e-03],\n",
      "         [ 2.37946212e-03,  1.48836523e-04,  1.82776526e-02, ...,\n",
      "           4.78562489e-02,  1.03296191e-02,  1.53523758e-02],\n",
      "         [ 2.19260156e-02,  1.57559589e-02, -2.42157821e-02, ...,\n",
      "          -2.85662208e-02,  4.03626412e-02, -4.72036339e-02],\n",
      "         ...,\n",
      "         [-3.05245686e-02, -3.74272391e-02,  4.06884626e-02, ...,\n",
      "           6.77131861e-03,  4.28437442e-03, -1.38088576e-02],\n",
      "         [ 3.99608165e-02,  2.98666060e-02,  1.03672370e-02, ...,\n",
      "          -3.65611389e-02, -1.60208941e-02, -2.90516634e-02],\n",
      "         [ 1.57864019e-02, -1.84991881e-02, -4.62342724e-02, ...,\n",
      "           3.69829237e-02, -1.72141604e-02,  3.45564485e-02]],\n",
      "\n",
      "        [[ 1.14250854e-02,  2.08452865e-02, -4.43980098e-05, ...,\n",
      "           4.41817194e-03, -3.97881120e-02, -1.79131627e-02],\n",
      "         [ 3.80371809e-02, -1.40706860e-02,  1.84816569e-02, ...,\n",
      "          -2.09621992e-02,  3.05358991e-02,  4.91115376e-02],\n",
      "         [-2.05079094e-03, -4.25888225e-02, -3.68837751e-02, ...,\n",
      "          -1.81190856e-02,  1.23007670e-02,  1.56599209e-02],\n",
      "         ...,\n",
      "         [ 3.81439924e-02,  1.88177228e-02, -1.33033767e-02, ...,\n",
      "          -4.33728993e-02, -1.75988600e-02,  4.13902178e-02],\n",
      "         [ 3.21011692e-02,  4.36051339e-02, -1.36449113e-02, ...,\n",
      "          -2.14746632e-02,  9.43739340e-03,  1.06888637e-03],\n",
      "         [ 2.28236243e-02,  4.87686917e-02, -2.42993552e-02, ...,\n",
      "          -4.43357974e-02, -3.45281214e-02, -4.14782688e-02]],\n",
      "\n",
      "        [[-3.70174646e-04, -2.95627154e-02,  3.16431299e-02, ...,\n",
      "           2.60525495e-02, -2.88541615e-03,  4.81844321e-02],\n",
      "         [-1.52224153e-02, -7.02253729e-03,  9.45475698e-03, ...,\n",
      "          -4.26444747e-02, -4.39003631e-02,  3.04713398e-02],\n",
      "         [-5.00131436e-02, -2.07527112e-02, -2.12184917e-02, ...,\n",
      "           3.89011204e-02, -4.78637889e-02,  1.17073432e-02],\n",
      "         ...,\n",
      "         [-4.31426801e-02,  2.86644176e-02,  3.71291786e-02, ...,\n",
      "           2.47873366e-02, -1.90121494e-02, -2.70827413e-02],\n",
      "         [ 6.66747615e-03,  2.14781389e-02,  3.85909677e-02, ...,\n",
      "          -1.45021677e-02,  2.19555199e-03, -4.19958308e-02],\n",
      "         [ 9.03271139e-04,  5.43012843e-03, -6.28250837e-03, ...,\n",
      "          -3.24133784e-04, -3.93085591e-02, -2.56088004e-03]]],\n",
      "\n",
      "\n",
      "       [[[ 4.16266173e-02,  1.16939023e-02, -1.63997896e-02, ...,\n",
      "           1.08762197e-02,  2.11615115e-03, -4.71724868e-02],\n",
      "         [-4.97169793e-02, -3.71206626e-02,  3.75450775e-02, ...,\n",
      "          -4.75630388e-02,  2.02238932e-02,  3.65954340e-02],\n",
      "         [ 3.65342945e-03,  1.84759349e-02,  1.65044963e-02, ...,\n",
      "           4.60119620e-02, -2.30070148e-02, -3.04821674e-02],\n",
      "         ...,\n",
      "         [ 1.61604360e-02, -3.16651314e-02, -4.29888181e-02, ...,\n",
      "          -4.99329045e-02,  7.37110153e-03, -2.11610775e-02],\n",
      "         [-6.10449538e-03,  2.00246423e-02,  5.04913330e-02, ...,\n",
      "          -2.24106014e-02, -1.80446841e-02,  1.44893900e-02],\n",
      "         [ 2.80872434e-02,  4.79871109e-02,  5.75522333e-03, ...,\n",
      "           4.98866737e-02,  2.63676047e-02, -4.02694158e-02]],\n",
      "\n",
      "        [[-2.64934339e-02,  3.69649157e-02,  1.24771371e-02, ...,\n",
      "           2.21439674e-02, -3.68964151e-02, -1.49390027e-02],\n",
      "         [-1.09275021e-02, -1.86946988e-03, -2.44864672e-02, ...,\n",
      "           4.15677205e-02,  1.48262680e-02, -9.88312066e-03],\n",
      "         [ 4.59377691e-02,  1.25464797e-03,  1.57298073e-02, ...,\n",
      "          -3.48852798e-02, -5.78251481e-03,  4.38785478e-02],\n",
      "         ...,\n",
      "         [-2.65170000e-02,  1.54923722e-02,  8.70167091e-03, ...,\n",
      "           2.42887810e-02, -4.71697263e-02,  2.15013921e-02],\n",
      "         [-3.29198241e-02, -1.05500668e-02,  1.54981092e-02, ...,\n",
      "           1.63039416e-02,  3.14196497e-02,  3.44716460e-02],\n",
      "         [ 4.17397767e-02, -3.63564454e-02,  1.91248357e-02, ...,\n",
      "          -1.08189136e-02, -4.98062223e-02,  1.35508403e-02]],\n",
      "\n",
      "        [[-9.12843272e-03,  2.63072327e-02,  3.65555137e-02, ...,\n",
      "          -3.46170515e-02,  1.35292187e-02, -2.72366032e-02],\n",
      "         [ 2.81843916e-03, -4.35993448e-02, -1.64245255e-02, ...,\n",
      "          -3.63998562e-02,  1.82556584e-02,  1.59993768e-03],\n",
      "         [-2.45230161e-02,  1.93660185e-02, -1.25328824e-02, ...,\n",
      "          -1.85660198e-02, -4.17868048e-03,  3.95073742e-02],\n",
      "         ...,\n",
      "         [-3.27475928e-02, -2.45475806e-02,  3.69650498e-02, ...,\n",
      "          -2.55504735e-02, -2.48084851e-02,  2.48564333e-02],\n",
      "         [-1.30774044e-02, -7.66080618e-03,  3.08684111e-02, ...,\n",
      "          -4.56678495e-02,  4.88116592e-03, -1.41094476e-02],\n",
      "         [-1.48027837e-02, -3.87939550e-02,  9.49591398e-03, ...,\n",
      "           3.44827250e-02, -1.45692900e-02,  2.45959684e-02]]]],\n",
      "      dtype=float32)>, <tf.Variable 'conv2d_13/bias:0' shape=(96,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'batch_normalization_12/gamma:0' shape=(48,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "      dtype=float32)>, <tf.Variable 'batch_normalization_12/beta:0' shape=(48,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>, <tf.Variable 'batch_normalization_13/gamma:0' shape=(96,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'batch_normalization_13/beta:0' shape=(96,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_14/kernel:0' shape=(3, 3, 144, 96) dtype=float32, numpy=\n",
      "array([[[[-0.02558593,  0.0446496 ,  0.00782768, ...,  0.0214378 ,\n",
      "          -0.03053314,  0.04963217],\n",
      "         [ 0.00048168,  0.04246294,  0.00520417, ...,  0.01976612,\n",
      "          -0.00355867,  0.04075655],\n",
      "         [ 0.01559188, -0.0247414 ,  0.01081201, ...,  0.03821502,\n",
      "           0.01650356, -0.03189261],\n",
      "         ...,\n",
      "         [-0.04893716,  0.01026203, -0.01373291, ...,  0.02893756,\n",
      "           0.03278032,  0.03218265],\n",
      "         [-0.04277474,  0.02420284,  0.0009152 , ..., -0.03105789,\n",
      "          -0.03212874,  0.00648128],\n",
      "         [ 0.00320029,  0.03063284,  0.00269172, ..., -0.04167622,\n",
      "           0.04871222, -0.04619934]],\n",
      "\n",
      "        [[ 0.00354303,  0.03511519, -0.03745019, ..., -0.01075897,\n",
      "          -0.01156956, -0.01865016],\n",
      "         [ 0.04325822, -0.0037737 , -0.04496524, ...,  0.0153022 ,\n",
      "          -0.01967399, -0.01356205],\n",
      "         [ 0.00164219, -0.00694399, -0.02513327, ...,  0.00424552,\n",
      "          -0.03605674, -0.02206896],\n",
      "         ...,\n",
      "         [-0.0189575 ,  0.01374272, -0.04056687, ..., -0.00250554,\n",
      "           0.03423077, -0.00242801],\n",
      "         [ 0.00485036, -0.02893009,  0.01943984, ..., -0.0169359 ,\n",
      "          -0.00360523, -0.03423858],\n",
      "         [ 0.04589486,  0.05122456, -0.05160976, ..., -0.03235958,\n",
      "           0.04405128, -0.03323521]],\n",
      "\n",
      "        [[ 0.03065133,  0.0274961 ,  0.03087008, ..., -0.04421989,\n",
      "           0.03603781,  0.0411259 ],\n",
      "         [ 0.02105449,  0.04748238, -0.00764984, ...,  0.00120165,\n",
      "           0.03622913,  0.04790951],\n",
      "         [ 0.01583981,  0.04321308, -0.00942353, ..., -0.00757639,\n",
      "           0.04160002,  0.04512069],\n",
      "         ...,\n",
      "         [-0.01209305,  0.03251901,  0.04705138, ..., -0.00335464,\n",
      "          -0.0226139 , -0.02520167],\n",
      "         [-0.02308857,  0.01013425,  0.00325818, ...,  0.01379506,\n",
      "          -0.04423642,  0.00212193],\n",
      "         [-0.01110361, -0.02038688, -0.03756204, ...,  0.01645831,\n",
      "          -0.03460293, -0.02243695]]],\n",
      "\n",
      "\n",
      "       [[[ 0.01574308,  0.02478725, -0.04034134, ..., -0.01577312,\n",
      "           0.04476846, -0.00462345],\n",
      "         [ 0.02439163, -0.05084669, -0.03174893, ..., -0.0346906 ,\n",
      "          -0.01628167, -0.02655205],\n",
      "         [-0.04831633,  0.02119565, -0.02254481, ..., -0.03328542,\n",
      "           0.04639402,  0.01855059],\n",
      "         ...,\n",
      "         [ 0.05020022, -0.03841269,  0.04886371, ...,  0.04942744,\n",
      "           0.0061745 , -0.02774213],\n",
      "         [-0.02389473,  0.01835736,  0.04908841, ..., -0.02712814,\n",
      "          -0.05101152, -0.03832516],\n",
      "         [ 0.04121178,  0.01572526, -0.02620203, ..., -0.01575723,\n",
      "           0.04742749, -0.04261384]],\n",
      "\n",
      "        [[-0.01003543, -0.02856886,  0.00808215, ..., -0.00187063,\n",
      "          -0.02924209, -0.0115647 ],\n",
      "         [ 0.01751225,  0.04220655,  0.0125952 , ...,  0.03877701,\n",
      "           0.05174232,  0.02985987],\n",
      "         [-0.00759149, -0.04765752, -0.04664113, ..., -0.01368089,\n",
      "           0.02732171, -0.04861638],\n",
      "         ...,\n",
      "         [-0.03648179, -0.03438548, -0.03581286, ..., -0.03630186,\n",
      "           0.03899264, -0.01150078],\n",
      "         [ 0.00742402,  0.03067951,  0.01231229, ...,  0.04855933,\n",
      "          -0.0348807 ,  0.02568023],\n",
      "         [-0.03847378,  0.04232413, -0.03272159, ..., -0.02650911,\n",
      "          -0.02977093, -0.00883093]],\n",
      "\n",
      "        [[ 0.04593828, -0.01646983,  0.02904474, ...,  0.00922512,\n",
      "          -0.03780376,  0.03140676],\n",
      "         [-0.00871846,  0.01791804,  0.0399847 , ..., -0.0365409 ,\n",
      "          -0.03167962,  0.00232198],\n",
      "         [-0.02973379, -0.0256178 ,  0.04058478, ..., -0.00520557,\n",
      "           0.04977283, -0.00211522],\n",
      "         ...,\n",
      "         [-0.00139567,  0.02645133,  0.02657401, ...,  0.00080536,\n",
      "          -0.02959766, -0.04182371],\n",
      "         [-0.01459061,  0.00565325,  0.01938738, ...,  0.03396654,\n",
      "           0.03085027, -0.04187019],\n",
      "         [ 0.03446139, -0.04808196,  0.02354391, ..., -0.01064941,\n",
      "           0.04713237,  0.03234727]]],\n",
      "\n",
      "\n",
      "       [[[ 0.05006342,  0.01377489, -0.0160748 , ...,  0.01777837,\n",
      "          -0.02018278,  0.01345636],\n",
      "         [-0.00171467, -0.00310976, -0.04198136, ...,  0.0311134 ,\n",
      "          -0.02333091, -0.037478  ],\n",
      "         [-0.02314371, -0.04260753, -0.00742777, ..., -0.04458116,\n",
      "           0.0443951 ,  0.04500734],\n",
      "         ...,\n",
      "         [ 0.02105411, -0.02784969, -0.00686964, ...,  0.05092594,\n",
      "           0.04381874,  0.01197047],\n",
      "         [ 0.03638163,  0.0075586 ,  0.02120003, ...,  0.01430916,\n",
      "           0.00117364, -0.00621236],\n",
      "         [-0.03222256, -0.0018456 ,  0.03671267, ...,  0.00695758,\n",
      "          -0.00781452, -0.00594922]],\n",
      "\n",
      "        [[-0.03440006, -0.04746796,  0.02618298, ...,  0.01789176,\n",
      "          -0.02934526, -0.00083677],\n",
      "         [-0.0272771 ,  0.03265372,  0.03799252, ..., -0.00539977,\n",
      "          -0.00361145, -0.04909618],\n",
      "         [ 0.04095257, -0.02703048, -0.00756123, ...,  0.01292479,\n",
      "          -0.01930064, -0.00797163],\n",
      "         ...,\n",
      "         [ 0.04464967,  0.03564482, -0.01586553, ...,  0.03175276,\n",
      "           0.00888357, -0.00483118],\n",
      "         [ 0.00265488,  0.00391265,  0.01292767, ...,  0.05199953,\n",
      "          -0.03588542,  0.03212525],\n",
      "         [ 0.01891841, -0.0359861 ,  0.0334045 , ..., -0.03838153,\n",
      "           0.00055169,  0.01440253]],\n",
      "\n",
      "        [[-0.00663417, -0.00676664,  0.01394725, ..., -0.0386884 ,\n",
      "           0.03008096, -0.00054772],\n",
      "         [ 0.00123627, -0.05037326, -0.02401476, ...,  0.01334774,\n",
      "          -0.03507734,  0.03915451],\n",
      "         [-0.03637103, -0.00310828, -0.02716849, ...,  0.01763755,\n",
      "          -0.04574894,  0.01674055],\n",
      "         ...,\n",
      "         [ 0.02372148, -0.00163729, -0.00058706, ..., -0.050626  ,\n",
      "           0.04052971, -0.04168292],\n",
      "         [ 0.04311756,  0.03531913, -0.00940686, ...,  0.0163867 ,\n",
      "           0.03740853, -0.03142691],\n",
      "         [ 0.00811268,  0.02148418, -0.03812523, ...,  0.04129941,\n",
      "           0.04670918,  0.04714035]]]], dtype=float32)>, <tf.Variable 'conv2d_14/bias:0' shape=(96,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'batch_normalization_14/gamma:0' shape=(96,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'batch_normalization_14/beta:0' shape=(96,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_15/kernel:0' shape=(1, 1, 240, 176) dtype=float32, numpy=\n",
      "array([[[[-0.05830172,  0.10174142,  0.01783665, ...,  0.06822099,\n",
      "          -0.0480382 , -0.11847121],\n",
      "         [-0.01699852, -0.04960475, -0.04862043, ..., -0.0327995 ,\n",
      "           0.09741454, -0.01562176],\n",
      "         [ 0.11895807,  0.06634635,  0.1025535 , ..., -0.11033416,\n",
      "          -0.03462262,  0.05652115],\n",
      "         ...,\n",
      "         [ 0.01295123, -0.1112343 , -0.09159236, ...,  0.10976508,\n",
      "           0.05678852, -0.06109878],\n",
      "         [-0.00814021, -0.02678204,  0.05421537, ...,  0.04751369,\n",
      "          -0.09114904,  0.03196089],\n",
      "         [-0.05759804,  0.0608065 , -0.09666212, ..., -0.08293112,\n",
      "          -0.00812045, -0.11413372]]]], dtype=float32)>, <tf.Variable 'conv2d_15/bias:0' shape=(176,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_16/kernel:0' shape=(3, 3, 240, 160) dtype=float32, numpy=\n",
      "array([[[[-0.01981878,  0.03458543,  0.00606329, ..., -0.01417612,\n",
      "          -0.0200544 ,  0.03376214],\n",
      "         [-0.03121439, -0.00924101,  0.03646195, ..., -0.01217789,\n",
      "          -0.00587023,  0.01201036],\n",
      "         [-0.02783256,  0.01845995,  0.03589185, ...,  0.03822757,\n",
      "           0.01773737, -0.03172844],\n",
      "         ...,\n",
      "         [-0.02016795, -0.03795375,  0.01586413, ...,  0.02747796,\n",
      "           0.03327183,  0.02741871],\n",
      "         [ 0.00693718, -0.02959032, -0.03298723, ..., -0.04078496,\n",
      "           0.02617621, -0.03287202],\n",
      "         [ 0.01950088, -0.00943651,  0.01293986, ...,  0.00504407,\n",
      "           0.00427149, -0.02635207]],\n",
      "\n",
      "        [[-0.02142576,  0.01893109,  0.03378646, ...,  0.00104577,\n",
      "          -0.00759605,  0.03493665],\n",
      "         [ 0.00452754,  0.00190527, -0.00085609, ...,  0.03397601,\n",
      "          -0.03771451,  0.03005648],\n",
      "         [ 0.03696425, -0.01304542,  0.00597695, ...,  0.00218069,\n",
      "           0.01685523,  0.03511788],\n",
      "         ...,\n",
      "         [-0.0011243 , -0.01739475, -0.03849582, ...,  0.02067622,\n",
      "          -0.02684019, -0.02500731],\n",
      "         [ 0.00863337, -0.02894425, -0.04006081, ..., -0.04064099,\n",
      "           0.001074  , -0.0389694 ],\n",
      "         [ 0.03728554,  0.00594515,  0.00099566, ..., -0.03546864,\n",
      "          -0.0276225 , -0.03318261]],\n",
      "\n",
      "        [[-0.00029614, -0.02365017,  0.0253145 , ...,  0.00354203,\n",
      "          -0.01930625, -0.01373049],\n",
      "         [-0.02517869, -0.01023492, -0.00468728, ...,  0.02893008,\n",
      "          -0.03601287, -0.02570339],\n",
      "         [-0.01377056, -0.01723877, -0.0251542 , ..., -0.03918302,\n",
      "           0.0029033 ,  0.01476957],\n",
      "         ...,\n",
      "         [ 0.03009089,  0.0140544 ,  0.02271229, ...,  0.01124103,\n",
      "           0.03325529,  0.00276604],\n",
      "         [ 0.0075226 , -0.0267886 , -0.02381874, ..., -0.00983202,\n",
      "           0.02868298,  0.00032264],\n",
      "         [ 0.01091776, -0.02004752, -0.00373954, ...,  0.04022855,\n",
      "           0.00424583, -0.01973212]]],\n",
      "\n",
      "\n",
      "       [[[ 0.02886844,  0.03385402,  0.03881391, ...,  0.00306731,\n",
      "          -0.02957469,  0.01036984],\n",
      "         [-0.00328737, -0.0185294 , -0.00991357, ..., -0.02542127,\n",
      "          -0.0385668 ,  0.0140597 ],\n",
      "         [ 0.02921411, -0.00674194, -0.04023221, ...,  0.00763081,\n",
      "          -0.01292232, -0.04032501],\n",
      "         ...,\n",
      "         [-0.00849351, -0.00051244,  0.03149959, ..., -0.03733945,\n",
      "          -0.02725978, -0.03306008],\n",
      "         [-0.02517656, -0.0245498 , -0.01717696, ...,  0.02974756,\n",
      "          -0.03073374,  0.01492336],\n",
      "         [-0.02920395, -0.02663261, -0.01352567, ...,  0.02603197,\n",
      "           0.01199971, -0.00027025]],\n",
      "\n",
      "        [[-0.04050546, -0.01972712, -0.03185184, ..., -0.02793532,\n",
      "          -0.01119561,  0.03802877],\n",
      "         [-0.02695112, -0.03200282, -0.01114579, ...,  0.03887123,\n",
      "          -0.00886362, -0.02794712],\n",
      "         [ 0.00106772,  0.03491226, -0.03298484, ..., -0.0105257 ,\n",
      "          -0.01684244, -0.02356102],\n",
      "         ...,\n",
      "         [-0.01215525, -0.03546267, -0.03424918, ..., -0.03294103,\n",
      "          -0.01455306, -0.0022615 ],\n",
      "         [-0.00751083, -0.01140175,  0.02205218, ..., -0.02043482,\n",
      "          -0.03559601, -0.02189633],\n",
      "         [-0.03995568, -0.03823316, -0.02807447, ..., -0.01912908,\n",
      "           0.00978266, -0.03309407]],\n",
      "\n",
      "        [[-0.00078898,  0.02382462, -0.02880403, ..., -0.01825771,\n",
      "          -0.02223628,  0.02491482],\n",
      "         [-0.0111245 , -0.02169718,  0.0379985 , ..., -0.03057482,\n",
      "          -0.00631386,  0.02365851],\n",
      "         [-0.0200782 , -0.0066211 ,  0.01625735, ...,  0.01632509,\n",
      "          -0.01219547, -0.00234161],\n",
      "         ...,\n",
      "         [-0.0186919 , -0.03085216,  0.02904855, ..., -0.03600989,\n",
      "          -0.01643403,  0.00905032],\n",
      "         [ 0.01414452, -0.02508092,  0.03614265, ..., -0.03746277,\n",
      "          -0.0153303 ,  0.00946299],\n",
      "         [ 0.02327115,  0.01439967, -0.02573914, ...,  0.04043845,\n",
      "           0.01235208,  0.02917048]]],\n",
      "\n",
      "\n",
      "       [[[ 0.03004773, -0.01829787,  0.03181105, ..., -0.03138005,\n",
      "          -0.0304669 ,  0.03423113],\n",
      "         [ 0.01178114, -0.02557962, -0.03361481, ...,  0.0133086 ,\n",
      "           0.03746766, -0.0270466 ],\n",
      "         [ 0.00524918,  0.01083792,  0.00443216, ..., -0.01636998,\n",
      "          -0.03987186,  0.00511654],\n",
      "         ...,\n",
      "         [ 0.00484798, -0.01534494, -0.01732859, ...,  0.00449105,\n",
      "           0.0261723 , -0.03216998],\n",
      "         [-0.02309472,  0.03282029, -0.02769621, ..., -0.00937866,\n",
      "          -0.01087293,  0.00066444],\n",
      "         [ 0.03489959, -0.01922338,  0.02036109, ..., -0.01179052,\n",
      "          -0.02931979,  0.00490074]],\n",
      "\n",
      "        [[-0.03116029, -0.02757779,  0.00479575, ...,  0.00072512,\n",
      "           0.00628708,  0.00041474],\n",
      "         [ 0.0173071 ,  0.02220722, -0.03323999, ..., -0.03840942,\n",
      "           0.01637702,  0.01603285],\n",
      "         [ 0.02052723, -0.02858299,  0.03311905, ...,  0.0016292 ,\n",
      "           0.03419033, -0.0006748 ],\n",
      "         ...,\n",
      "         [-0.00614264, -0.01771564, -0.03060344, ..., -0.0356602 ,\n",
      "          -0.00803863, -0.03607374],\n",
      "         [ 0.01799826, -0.02980008, -0.00423968, ...,  0.0015651 ,\n",
      "           0.03474064,  0.03607385],\n",
      "         [-0.02126029,  0.01203286,  0.0159528 , ...,  0.02181733,\n",
      "          -0.0330912 ,  0.03234877]],\n",
      "\n",
      "        [[-0.0287604 , -0.01310792,  0.00165484, ..., -0.00014031,\n",
      "          -0.00920114,  0.02508984],\n",
      "         [-0.03320704, -0.02302553,  0.02802265, ..., -0.03411683,\n",
      "          -0.02335307, -0.01846559],\n",
      "         [-0.01736081, -0.00820652, -0.00255514, ...,  0.01853921,\n",
      "           0.03851981, -0.00352323],\n",
      "         ...,\n",
      "         [-0.01741432,  0.02758309,  0.02781518, ..., -0.00951135,\n",
      "          -0.01276145,  0.01005401],\n",
      "         [-0.00682192, -0.03224582, -0.0081773 , ...,  0.03384823,\n",
      "          -0.00698676, -0.02136254],\n",
      "         [ 0.02456383,  0.03261732, -0.02111137, ...,  0.01697668,\n",
      "          -0.03795322,  0.00784206]]]], dtype=float32)>, <tf.Variable 'conv2d_16/bias:0' shape=(160,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'batch_normalization_15/gamma:0' shape=(176,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'batch_normalization_15/beta:0' shape=(176,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'batch_normalization_16/gamma:0' shape=(160,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'batch_normalization_16/beta:0' shape=(160,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_17/kernel:0' shape=(1, 1, 336, 176) dtype=float32, numpy=\n",
      "array([[[[-0.05255246,  0.09170846,  0.01607773, ...,  0.06149357,\n",
      "          -0.04330105, -0.10678851],\n",
      "         [-0.01532226, -0.04471312, -0.04382586, ..., -0.02956507,\n",
      "           0.08780827, -0.01408126],\n",
      "         [ 0.10722735,  0.05980379,  0.09244048, ..., -0.09945387,\n",
      "          -0.03120841,  0.05094747],\n",
      "         ...,\n",
      "         [ 0.00312407, -0.04903206,  0.10473765, ..., -0.04433039,\n",
      "          -0.07664455, -0.01588628],\n",
      "         [-0.05736264,  0.10511319, -0.00116742, ...,  0.08079723,\n",
      "          -0.0855189 , -0.0827932 ],\n",
      "         [-0.03331479,  0.04963247, -0.04684883, ...,  0.09587922,\n",
      "          -0.05693268, -0.01622658]]]], dtype=float32)>, <tf.Variable 'conv2d_17/bias:0' shape=(176,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_18/kernel:0' shape=(3, 3, 336, 160) dtype=float32, numpy=\n",
      "array([[[[-0.01779778,  0.03105863,  0.005445  , ..., -0.01273053,\n",
      "          -0.01800938,  0.03031929],\n",
      "         [-0.02803135, -0.00829868,  0.0327438 , ..., -0.01093607,\n",
      "          -0.00527162,  0.01078562],\n",
      "         [-0.02499438,  0.01657753,  0.03223183, ...,  0.03432937,\n",
      "           0.01592862, -0.02849297],\n",
      "         ...,\n",
      "         [-0.02486626,  0.00386609,  0.02247756, ..., -0.0163501 ,\n",
      "          -0.02691818,  0.00725559],\n",
      "         [-0.02275446,  0.0037916 , -0.01126068, ..., -0.00247572,\n",
      "          -0.00222487, -0.00643806],\n",
      "         [-0.00418065, -0.02878823, -0.01788372, ...,  0.00683039,\n",
      "           0.02301152, -0.03263871]],\n",
      "\n",
      "        [[-0.02851874, -0.01296421,  0.01313576, ..., -0.01879852,\n",
      "           0.02403956, -0.0163821 ],\n",
      "         [-0.02541658, -0.01856896, -0.01776777, ..., -0.01979276,\n",
      "          -0.00584758,  0.02984529],\n",
      "         [-0.00740187,  0.00994276, -0.01776062, ..., -0.03608954,\n",
      "           0.02137513,  0.0175123 ],\n",
      "         ...,\n",
      "         [ 0.03665805, -0.02606172, -0.00240561, ...,  0.00792853,\n",
      "          -0.02202481, -0.00079758],\n",
      "         [-0.00743072, -0.00557262, -0.00463789, ..., -0.0186981 ,\n",
      "          -0.01085854, -0.0140424 ],\n",
      "         [-0.02127733,  0.00927602,  0.00881917, ...,  0.03583964,\n",
      "           0.01894305, -0.0289304 ]],\n",
      "\n",
      "        [[-0.01903344,  0.02655638,  0.00896384, ..., -0.00816729,\n",
      "           0.02380894,  0.02370397],\n",
      "         [ 0.01361142,  0.02459906,  0.00378622, ...,  0.02544568,\n",
      "           0.01103071,  0.03046439],\n",
      "         [ 0.03203897,  0.00453202, -0.03223248, ..., -0.03139936,\n",
      "          -0.02999817,  0.02814302],\n",
      "         ...,\n",
      "         [ 0.02781128,  0.00570409,  0.00487334, ..., -0.0134626 ,\n",
      "           0.03573192,  0.0278886 ],\n",
      "         [ 0.0199809 , -0.0344629 , -0.02134759, ..., -0.00976438,\n",
      "           0.00667005, -0.01246989],\n",
      "         [ 0.03176512, -0.02044141, -0.02843041, ...,  0.01817153,\n",
      "           0.0186918 , -0.00588511]]],\n",
      "\n",
      "\n",
      "       [[[ 0.03199815,  0.02079958, -0.02770214, ..., -0.02845464,\n",
      "           0.0157268 ,  0.01078852],\n",
      "         [ 0.00200304,  0.01088813,  0.01192824, ..., -0.00814999,\n",
      "           0.00596611,  0.0340701 ],\n",
      "         [ 0.03380291, -0.03314869,  0.02989857, ..., -0.00411468,\n",
      "          -0.01059394, -0.02992497],\n",
      "         ...,\n",
      "         [ 0.00455172,  0.01335456,  0.01662073, ..., -0.02572944,\n",
      "          -0.01259284, -0.03045207],\n",
      "         [-0.02965514, -0.0262779 , -0.02056269, ..., -0.0351503 ,\n",
      "          -0.01181216,  0.03060118],\n",
      "         [-0.03324201,  0.01422172, -0.02580624, ..., -0.00547959,\n",
      "          -0.0060528 , -0.02208272]],\n",
      "\n",
      "        [[ 0.00959214, -0.03552062, -0.03641074, ..., -0.0128675 ,\n",
      "           0.02126903,  0.00839028],\n",
      "         [ 0.00928777,  0.03019733,  0.03312156, ...,  0.03608053,\n",
      "          -0.00275511,  0.02357138],\n",
      "         [-0.01344331, -0.03590738,  0.03480325, ..., -0.02411378,\n",
      "           0.03188426,  0.00987771],\n",
      "         ...,\n",
      "         [ 0.00435362, -0.01378016, -0.01556153, ...,  0.00403308,\n",
      "           0.02350342, -0.02888949],\n",
      "         [-0.02073967,  0.02947349, -0.02487193, ..., -0.00842229,\n",
      "          -0.00976418,  0.00059668],\n",
      "         [ 0.03134076, -0.01726311,  0.0182848 , ..., -0.0105882 ,\n",
      "          -0.02632995,  0.00440099]],\n",
      "\n",
      "        [[-0.02798276, -0.02476559,  0.00430671, ...,  0.00065118,\n",
      "           0.00564596,  0.00037245],\n",
      "         [ 0.01554224,  0.01994267, -0.02985039, ..., -0.03449268,\n",
      "           0.014707  ,  0.01439793],\n",
      "         [ 0.018434  , -0.02566828,  0.02974179, ...,  0.00146307,\n",
      "           0.03070382, -0.00060599],\n",
      "         ...,\n",
      "         [-0.00849096, -0.0234805 , -0.0056859 , ..., -0.02043088,\n",
      "           0.03060573, -0.01835894],\n",
      "         [-0.00375675, -0.00342103, -0.02905254, ..., -0.00649674,\n",
      "          -0.01940779, -0.01933203],\n",
      "         [ 0.01405521, -0.00887881, -0.02519403, ..., -0.01623968,\n",
      "          -0.02076321, -0.00108947]]],\n",
      "\n",
      "\n",
      "       [[[-0.02931917, -0.02175473,  0.0039646 , ...,  0.02697348,\n",
      "          -0.02699978, -0.03281339],\n",
      "         [ 0.00337653,  0.03170492, -0.01715717, ...,  0.01274749,\n",
      "          -0.00950568, -0.00401105],\n",
      "         [-0.01502731,  0.00260702,  0.03619059, ..., -0.00981685,\n",
      "          -0.01930257,  0.02183169],\n",
      "         ...,\n",
      "         [ 0.02038583,  0.01468346,  0.01743119, ...,  0.01864932,\n",
      "          -0.0103209 , -0.0185836 ],\n",
      "         [-0.01114432,  0.00581079,  0.02035971, ...,  0.03549857,\n",
      "          -0.01998138, -0.02298687],\n",
      "         [-0.01215459, -0.02755595, -0.00725268, ..., -0.03579524,\n",
      "          -0.00259442, -0.00685756]],\n",
      "\n",
      "        [[ 0.01268339, -0.02461942,  0.00374407, ..., -0.03503754,\n",
      "          -0.01766971,  0.01162037],\n",
      "         [ 0.01921599,  0.02360232, -0.03658985, ..., -0.02213686,\n",
      "           0.00481808,  0.01479978],\n",
      "         [-0.02552113, -0.03405361,  0.01820891, ..., -0.03410878,\n",
      "           0.00495102,  0.01339524],\n",
      "         ...,\n",
      "         [ 0.01929341,  0.03653466,  0.03478571, ..., -0.01033677,\n",
      "           0.00141602, -0.01657036],\n",
      "         [-0.03645312, -0.0212135 , -0.02885739, ..., -0.00158456,\n",
      "          -0.03530035, -0.03551471],\n",
      "         [ 0.02841635, -0.03543264,  0.00832622, ..., -0.02935771,\n",
      "           0.00285994,  0.0330891 ]],\n",
      "\n",
      "        [[-0.02133476, -0.03042746,  0.02277641, ..., -0.03299965,\n",
      "          -0.01168801,  0.01992466],\n",
      "         [-0.03202864, -0.02477542, -0.01334627, ...,  0.01517212,\n",
      "           0.02763641,  0.00323553],\n",
      "         [-0.01393865, -0.03579319, -0.01764768, ..., -0.01800821,\n",
      "          -0.0311718 ,  0.012919  ],\n",
      "         ...,\n",
      "         [-0.01630716, -0.03331076, -0.01893202, ..., -0.01327101,\n",
      "           0.01653748, -0.00467261],\n",
      "         [ 0.01944938,  0.02657142, -0.02477141, ..., -0.02047582,\n",
      "           0.03351494, -0.00934052],\n",
      "         [ 0.01346561, -0.00359408,  0.01149756, ..., -0.03109623,\n",
      "           0.01313175, -0.02878343]]]], dtype=float32)>, <tf.Variable 'conv2d_18/bias:0' shape=(160,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'batch_normalization_17/gamma:0' shape=(176,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'batch_normalization_17/beta:0' shape=(176,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'batch_normalization_18/gamma:0' shape=(160,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'batch_normalization_18/beta:0' shape=(160,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'dense/kernel:0' shape=(336, 10) dtype=float32, numpy=\n",
      "array([[-0.06392784,  0.11155945,  0.01955788, ..., -0.03313883,\n",
      "         0.11031532, -0.0656869 ],\n",
      "       [ 0.12414505, -0.06098987,  0.10682873, ...,  0.12843592,\n",
      "         0.06575328,  0.08405776],\n",
      "       [-0.11855068,  0.01946561, -0.02145126, ...,  0.03334956,\n",
      "        -0.12857798, -0.01933933],\n",
      "       ...,\n",
      "       [ 0.07181513, -0.07137261, -0.00293633, ..., -0.02439507,\n",
      "         0.12101634, -0.12729628],\n",
      "       [-0.06282018,  0.00562875, -0.03949001, ...,  0.07869017,\n",
      "        -0.05106448,  0.07734197],\n",
      "       [-0.06935135, -0.1098613 ,  0.02303031, ...,  0.0207949 ,\n",
      "        -0.02196807,  0.08125018]], dtype=float32)>, <tf.Variable 'dense/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]\n",
      "4\n",
      "5\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "opt = SGD(1e-1, momentum=0.9)\n",
    "model = MiniGoogLeNet.build(width=img_witdth, height=img_height, depth=1, classes=10)\n",
    "history = {'loss': [], 'accuracy': [], 'val_loss': [], 'val_accuracy': [], 'batch_size': []}\n",
    "\n",
    "batch_size = 32\n",
    "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "for ep in range(20):\n",
    "    epoch_loss = tf.keras.metrics.Mean()\n",
    "    epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "    for i in range(int(np.ceil(train_size / batch_size))):\n",
    "        current_batch = trainX[i*batch_size:min(train_size, (i+1)*batch_size)]\n",
    "        current_label = trainY[i*batch_size:min(train_size, (i+1)*batch_size)]\n",
    "        # accum_gradient = [tf.Variable(tf.zeros_like(v, dtype=tf.float32), trainable=False) for v in model.trainable_variables]\n",
    "        for j in range(int(batch_size / 8)):\n",
    "            x = current_batch[i*8:min(batch_size, (i+1)*8)]\n",
    "            y = current_label[i*8:min(batch_size, (i+1)*8)]\n",
    "\n",
    "\n",
    "            # loss_value, grads = grad(model, x, y)\n",
    "            with tf.GradientTape() as tape:\n",
    "                prediction = model(x, training = True)\n",
    "                print(4)\n",
    "                loss_value = loss_object(y_true=y, y_pred=prediction)\n",
    "                print(5)\n",
    "            \n",
    "            # print(7)\n",
    "            # epoch_loss.update_state(loss_value) \n",
    "            # epoch_accuracy.update_state(y_true=y, y_pred=y_)\n",
    "            grads = tape.gradient(loss_value, model.trainable_variables)\n",
    "            print(5)\n",
    "            # for i in range(len(accum_gradient)):\n",
    "            #     accum_gradient[i].assign_add(grads[i])\n",
    "        \n",
    "        # accum_gradient = [this_grad/(batch_size / 32) for this_grad in accum_gradient]\n",
    "        # opt.apply_gradients(zip(accum_gradient, model.trainable_variables))\n",
    "        \n",
    "    # history['loss'].append(epoch_loss)\n",
    "    # history['accuracy'].append(epoch_accuracy.result())\n",
    "    # history['batch_size'].append(batch_size)\n",
    "\n",
    "    # epoch_val_loss = tf.keras.metrics.Mean()\n",
    "    # epoch_val_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "    # for _ in range(int(np.ceil(len(testX) / batch_size))):\n",
    "    #     predicted = []\n",
    "    #     true_labels = []\n",
    "    #     for _ in range(int(batch_size / 32)):\n",
    "    #         try:\n",
    "    #             x = a.next()\n",
    "    #             y = b.next()\n",
    "    #         except StopIteration:\n",
    "    #             break\n",
    "\n",
    "    #         y_ = model(x)\n",
    "    #         epoch_loss.update_state(keras.losses.categorical_crossentropy(y_true=y, y_pred=y_)) \n",
    "    #         epoch_accuracy.update_state(y_true=y, y_pred=y_)\n",
    "\n",
    "    # history['val_loss'].append(epoch_val_loss)\n",
    "    # history['val_accuracy'].append(epoch_val_accuracy.result())\n",
    "\n",
    "    if ep%10 == 9:\n",
    "        batch_size *= 2\n",
    "        print(ep, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 10)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "trainY[i*batch_size:min(train_size, (i+1)*batch_size)].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conv-1: $(11\\times11)\\times3\\times96 + 96 = 34944$\n",
    "\n",
    "Conv-2: $(5\\times5)\\times96\\times256 + 256 = 614656$\n",
    "\n",
    "Conv-3: $(3\\times3)\\times256\\times384 + 384 = 885120$\n",
    "\n",
    "Conv-4: $(3\\times3)\\times384\\times384 + 384 = 1327488$\n",
    "\n",
    "Conv-5: $(3\\times3)\\times384\\times256 + 256 = 884992$\n",
    "\n",
    "FC-1: $(6\\times6)\\times256\\times4096 + 4096 = 37752832$\n",
    "\n",
    "FC-2: $4096\\times4096 + 4096 = 16781312$\n",
    "\n",
    "FC-3: $4096\\times1000 + 1000 = 4097000$\n",
    "\n",
    "Total: $62378344$ parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 VGG19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Layer | Number of Activations (Memory) | Parameters (Compute) |\n",
    "|---|---|---|\n",
    "| Input | $224*224*3=150K$ | 0 | \n",
    "| CONV3-64 | $224*224*64=3.2M$ | $(3*3*3)*64 = 1,728$ |\n",
    "| CONV3-64 | $224*224*64=3.2M$ | $(3*3*64)*64 = 36,864$ |\n",
    "| POOL2 | $112*112*64=800K$ | 0 |\n",
    "| CONV3-128 |  |  |\n",
    "| CONV3-128 |  |  |\n",
    "| POOL2 | $56*56*128=400K$ | 0 |\n",
    "| CONV3-256 |  |  |\n",
    "| CONV3-256 | $56*56*256=800K$ | $(3*3*256)*256 = 589,824$ |\n",
    "| CONV3-256 |  |  |\n",
    "| CONV3-256 |  |  |\n",
    "| POOL2 |  | 0 |\n",
    "| CONV3-512 | $28*28*512=400K$ | $(3*3*256)*512 = 1,179,648$ |\n",
    "| CONV3-512 |  |  |\n",
    "| CONV3-512 | $28*28*512=400K$ |  |\n",
    "| CONV3-512 |  |  |\n",
    "| POOL2 |  | 0 |\n",
    "| CONV3-512 |  |  |\n",
    "| CONV3-512 |  |  |\n",
    "| CONV3-512 |  |  |\n",
    "| CONV3-512 |  |  |\n",
    "| POOL2 |  | 0 |\n",
    "| FC | 4096 |  |\n",
    "| FC | 4096 | $4096*4096 = 16,777,216$ |\n",
    "| FC | 1000 | $4096*1000 = 4096000$ |\n",
    "| Total |  |  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3\n",
    "\n",
    "Assume stride is 1 and padding is 0.\n",
    "\n",
    "For the 1st layer, the filter of size $F  F$ looks at $F  F$ of input, (i.e. receptive field $F  F$). The 2nd layer looks at $F  F$ of 1st layer, due to overlap of receptive fields the filter looking at, the first cell looks at $F  F$ of input, end each cell looks at an extra size equal to stride (i.e. $21$ will look at $(F + 1)  F$ of input)\n",
    "\n",
    "Since stride is 1, $F  F$ of 1st layer is equal to $(F + (F - 1)*1)  (F + (F - 1)*1)$ of input. The 3rd layer looks at $F  F$ of 2nd layer, which is equal to $(F + (F - 1)*1)  (F + (F - 1)*1)$ of 1st layer, which is equal to $(F + (2F - 2)*1)  (F + (2F - 2)*1)$ of input. \n",
    "\n",
    "So Nth layer fillter will look at $F  F$ of N-1th layer, which is equal to $(2F - 1)  (2F - 1)$ of N-2th layer, which is equal to $(3F - 2)  (3F - 2)$ of N-3th layer, ..., which is equal to $(NF - N + 1)  (NF - N + 1)$ of input. So stack of N convolution layers each of filter size $F  F$ has the same receptive field as one convolution layer with filter of size $(NF  N + 1)  (NF  N + 1)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec3a78e46a7458ecca355902d87ef79b66c022d7493199cd99646ac90a6100a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
